{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNMT_mr-hi-en.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FZEEYNZgPLi",
        "outputId": "47c7b917-403f-4789-e083-64649eb69388"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BE-G66Fui2n"
      },
      "source": [
        "!pip3 freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKsHZHiPga6x",
        "outputId": "f0920603-7d0d-485c-8c4b-e5045a2f8801"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  requirements.txt  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhmefQ8cgYYd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzpsQ31Kghgo",
        "outputId": "a1cdd84f-0675-4a03-c325-a7eca73b2d36"
      },
      "source": [
        "!wget https://storage.googleapis.com/samanantar-public/V0.2/data/en2indic/en-mr.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-06 06:33:15--  https://storage.googleapis.com/samanantar-public/V0.2/data/en2indic/en-mr.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.73.240, 142.250.65.80, 142.250.188.208, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.73.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 769637789 (734M) [application/zip]\n",
            "Saving to: ‘en-mr.zip’\n",
            "\n",
            "en-mr.zip           100%[===================>] 733.98M   179MB/s    in 4.2s    \n",
            "\n",
            "2021-07-06 06:33:20 (176 MB/s) - ‘en-mr.zip’ saved [769637789/769637789]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWRalAsGhVTO",
        "outputId": "2ece2db0-e58f-4e73-9515-6fd8e92ae6fe"
      },
      "source": [
        "!wget https://storage.googleapis.com/samanantar-public/V0.2/data/en2indic/en-hi.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-16 08:40:31--  https://storage.googleapis.com/samanantar-public/V0.2/data/en2indic/en-hi.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.101.128, 142.250.141.128, 142.251.2.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.101.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2853073724 (2.7G) [application/zip]\n",
            "Saving to: ‘en-hi.zip’\n",
            "\n",
            "en-hi.zip           100%[===================>]   2.66G  37.9MB/s    in 41s     \n",
            "\n",
            "2021-07-16 08:41:12 (67.1 MB/s) - ‘en-hi.zip’ saved [2853073724/2853073724]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xSTccqZhX3-",
        "outputId": "6c92e89f-6c7b-439e-d527-9f3671631e38"
      },
      "source": [
        "!unzip /content/en-hi.zip\n",
        "!unzip /content/en-mr.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/en-hi.zip\n",
            "   creating: en-hi/\n",
            " extracting: en-hi/train.hi          \n",
            " extracting: en-hi/train.en          \n",
            "Archive:  /content/en-mr.zip\n",
            "   creating: en-mr/\n",
            " extracting: en-mr/train.mr          \n",
            " extracting: en-mr/train.en          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xUfQDPyhcyJ",
        "outputId": "e712e120-e11a-432d-ecb3-b32389daf90a"
      },
      "source": [
        "%cd /content/en-hi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/en-hi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXXka9yriCN5"
      },
      "source": [
        "!split -l 8460000 /content/en-hi/hi-en.en split_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJl40CmCiGUu"
      },
      "source": [
        "!split -l 8460000 /content/en-hi/hi-en.hi split_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEAzMjgOisRt",
        "outputId": "d8990d3b-88ea-405a-8162-74606e3ce3b0"
      },
      "source": [
        "%cd /content/en-mr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/en-mr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNSU1ri-jOaD"
      },
      "source": [
        "!split -l 3280000 /content/en-mr/mr-en.en split_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5goG9LDVjc8C"
      },
      "source": [
        "!split -l 3280000 /content/en-mr/mr-en.mr split_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfSqA93YjsQ1",
        "outputId": "6132b572-359c-4117-90d0-7b874d19cbef"
      },
      "source": [
        "%cd /content/drive/MyDrive/MNMT(mr-hi-en)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MNMT(mr-hi-en)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPkqsXN-j4_a",
        "outputId": "3bc1ab0d-919a-4d96-bb70-5c0736250074"
      },
      "source": [
        "!pip install sacrebleu sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 7.2MB/s \n",
            "\u001b[?25hCollecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Installing collected packages: portalocker, sacrebleu, sentencepiece\n",
            "Successfully installed portalocker-2.0.0 sacrebleu-1.5.1 sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohRm9G_Jj8dR",
        "outputId": "0fa1b5b3-5be3-4095-df0d-52cec2abd08b"
      },
      "source": [
        "!git clone https://github.com/NLP-NMT/fairseq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 28461, done.\u001b[K\n",
            "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 28461 (delta 140), reused 213 (delta 104), pack-reused 28181\u001b[K\n",
            "Receiving objects: 100% (28461/28461), 12.01 MiB | 6.45 MiB/s, done.\n",
            "Resolving deltas: 100% (21336/21336), done.\n",
            "Checking out files: 100% (873/873), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QAiqDPpkJot",
        "outputId": "783e7c45-1d60-48b6-8e6d-66493ec00dad"
      },
      "source": [
        "%cd /content/drive/MyDrive/MNMT(mr-hi-en)/fairseq/examples/translation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MNMT(mr-hi-en)/fairseq/examples/translation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xxHqmtFly5K"
      },
      "source": [
        "!mkdir mr_hi.en.bpe16k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO7ypZzzmCkN"
      },
      "source": [
        "!mkdir orig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3MI4kSLmfkc"
      },
      "source": [
        "#Rename folder MNMT(mr-hi-en) to MNMT_mr-hi-en_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgTVhLtSmFDr"
      },
      "source": [
        "!mv /content/en-mr/train.mr-en.en  /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k\n",
        "!mv /content/en-mr/train.mr-en.mr  /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k\n",
        "!mv /content/en-mr/valid.mr-en.en  /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k\n",
        "!mv /content/en-mr/valid.mr-en.mr  /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj4AqTIRmaSV"
      },
      "source": [
        "!mv /content/en-hi/train.hi-en.en  /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k\n",
        "!mv /content/en-hi/train.hi-en.hi  /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k\n",
        "!mv /content/en-hi/valid.hi-en.en  /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k\n",
        "!mv /content/en-hi/valid.hi-en.hi  /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcAaNAYkocC1",
        "outputId": "4917a3ea-1f00-4c08-afaa-496fb65abb18"
      },
      "source": [
        "%cd /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCTZK-gFo0Sb",
        "outputId": "f753ea42-26a3-4a30-aafa-0dc1d50cf421"
      },
      "source": [
        "!bash prepare-iwslt17-multilingual.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning joint BPE over ./mr_hi.en.bpe16k/train.mr-en.mr,./mr_hi.en.bpe16k/train.mr-en.en,./mr_hi.en.bpe16k/train.hi-en.hi,./mr_hi.en.bpe16k/train.hi-en.en,...\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=./mr_hi.en.bpe16k/train.mr-en.mr,./mr_hi.en.bpe16k/train.mr-en.en,./mr_hi.en.bpe16k/train.hi-en.hi,./mr_hi.en.bpe16k/train.hi-en.en, --model_prefix=./mr_hi.en.bpe16k/sentencepiece.bpe --vocab_size=16384 --character_coverage=1.0 --model_type=bpe\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: ./mr_hi.en.bpe16k/train.mr-en.mr\n",
            "  input: ./mr_hi.en.bpe16k/train.mr-en.en\n",
            "  input: ./mr_hi.en.bpe16k/train.hi-en.hi\n",
            "  input: ./mr_hi.en.bpe16k/train.hi-en.en\n",
            "  input_format: \n",
            "  model_prefix: ./mr_hi.en.bpe16k/sentencepiece.bpe\n",
            "  model_type: BPE\n",
            "  vocab_size: 16384\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: ./mr_hi.en.bpe16k/train.mr-en.mr\n",
            "trainer_interface.cc(356) LOG(WARNING) Found too long line (5197 > 4192).\n",
            "trainer_interface.cc(358) LOG(WARNING) Too long lines are skipped in the training.\n",
            "trainer_interface.cc(359) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 1000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 2000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 3000000 lines\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: ./mr_hi.en.bpe16k/train.mr-en.en\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 4000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 5000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 6000000 lines\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: ./mr_hi.en.bpe16k/train.hi-en.hi\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 7000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 8000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 9000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 10000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 11000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 12000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 13000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 14000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 15000000 lines\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: ./mr_hi.en.bpe16k/train.hi-en.en\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 16000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 17000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 18000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 19000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 20000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 21000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 22000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 23000000 lines\n",
            "trainer_interface.cc(117) LOG(WARNING) Too many sentences are loaded! (23479787), which may slow down training.\n",
            "trainer_interface.cc(119) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
            "trainer_interface.cc(122) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
            "trainer_interface.cc(385) LOG(INFO) Loaded all 23479787 sentences\n",
            "trainer_interface.cc(391) LOG(INFO) Skipped 213 too long sentences.\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(466) LOG(INFO) all chars count=2031842444\n",
            "trainer_interface.cc(477) LOG(INFO) Done: 100% characters are covered.\n",
            "trainer_interface.cc(487) LOG(INFO) Alphabet size=3034\n",
            "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 23479787 sentences.\n",
            "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 23479787\n",
            "trainer_interface.cc(537) LOG(INFO) Done! 4192703\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=30142022 min_freq=113164\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8246278 size=20 all=26302 active=3045 piece=is\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5813007 size=40 all=28227 active=4970 piece=▁f\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4490325 size=60 all=30124 active=6867 piece=▁and\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3270563 size=80 all=32209 active=8952 piece=▁और\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2570228 size=100 all=34265 active=11008 piece=ही\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2483737 min_freq=133708\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2129903 size=120 all=36689 active=3970 piece=हा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1777350 size=140 all=39714 active=6995 piece=ir\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1508905 size=160 all=42308 active=9589 piece=ra\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1340620 size=180 all=44986 active=12267 piece=▁that\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1198042 size=200 all=48477 active=15758 piece=▁ha\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1189391 min_freq=82665\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1082824 size=220 all=51028 active=4928 piece=कार\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=992181 size=240 all=53817 active=7717 piece=सी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=902613 size=260 all=56593 active=10493 piece=▁at\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=837078 size=280 all=60128 active=14028 piece=um\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=748637 size=300 all=63012 active=16912 piece=▁this\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=748522 min_freq=58117\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=707299 size=320 all=66462 active=6570 piece=em\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=650026 size=340 all=70078 active=10186 piece=▁India\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=616909 size=360 all=73171 active=13279 piece=ive\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=584053 size=380 all=75627 active=15735 piece=मी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=546801 size=400 all=78798 active=18906 piece=स्त\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=546421 min_freq=42257\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=509341 size=420 all=82628 active=7475 piece=ian\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=482831 size=440 all=85945 active=10792 piece=▁हा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=454900 size=460 all=89154 active=14001 piece=▁inc\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=431790 size=480 all=93377 active=18224 piece=ार्\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=408937 size=500 all=96100 active=20947 piece=र्व\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=408935 min_freq=32564\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=392543 size=520 all=99150 active=7613 piece=▁अधिक\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=373028 size=540 all=102161 active=10624 piece=ary\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=357238 size=560 all=105757 active=14220 piece=one\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=347976 size=580 all=110178 active=18641 piece=▁ऐ\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=327910 size=600 all=112658 active=21121 piece=orm\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=327660 min_freq=25696\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=317387 size=620 all=115357 active=8142 piece=▁‘\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=307795 size=640 all=119208 active=11993 piece=▁स्थ\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=299988 size=660 all=121747 active=14532 piece=gh\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=288910 size=680 all=126276 active=19061 piece=▁comp\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=282784 size=700 all=128516 active=21301 piece=▁मुख\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=282053 min_freq=21162\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=271682 size=720 all=131146 active=8970 piece=ेत्र\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=264972 size=740 all=133614 active=11438 piece=▁work\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=258396 size=760 all=136331 active=14155 piece=जे\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=249697 size=780 all=139884 active=17708 piece=▁ऑ\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=243328 size=800 all=142632 active=20456 piece=ूल\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=243033 min_freq=17954\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=236088 size=820 all=145736 active=9959 piece=ंह\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=229579 size=840 all=148246 active=12469 piece=▁सह\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=222638 size=860 all=151823 active=16046 piece=▁new\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=217327 size=880 all=154535 active=18758 piece=तील\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=210899 size=900 all=157427 active=21650 piece=▁inv\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=210006 min_freq=15491\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=204784 size=920 all=159955 active=10370 piece=▁All\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=199242 size=940 all=162559 active=12974 piece=ड़े\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=194457 size=960 all=166196 active=16611 piece=िप\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=190527 size=980 all=169334 active=19749 piece=्स\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=186336 size=1000 all=171893 active=22308 piece=▁should\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=185619 min_freq=13542\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=182226 size=1020 all=175069 active=11751 piece=दर्\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=176617 size=1040 all=177701 active=14383 piece=ents\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=173676 size=1060 all=180854 active=17536 piece=▁खिला\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=168990 size=1080 all=183210 active=19892 piece=man\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=166228 size=1100 all=186036 active=22718 piece=ndra\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=166155 min_freq=11998\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=163355 size=1120 all=188362 active=11547 piece=ple\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=160211 size=1140 all=191033 active=14218 piece=▁गो\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=157443 size=1160 all=193437 active=16622 piece=▁प्रदेश\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=153537 size=1180 all=195626 active=18811 piece=gr\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=150569 size=1200 all=199140 active=22325 piece=▁बीच\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=150419 min_freq=10766\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=147648 size=1220 all=202362 active=13127 piece=▁What\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=144133 size=1240 all=205148 active=15913 piece=▁ची\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=141532 size=1260 all=207889 active=18654 piece=ful\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=139140 size=1280 all=210706 active=21471 piece=▁So\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=137131 size=1300 all=213633 active=24398 piece=fore\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=136755 min_freq=9590\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=134662 size=1320 all=216254 active=13220 piece=▁महिला\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=131738 size=1340 all=218165 active=15131 piece=ower\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=129256 size=1360 all=220306 active=17272 piece=ible\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=127223 size=1380 all=223415 active=20381 piece=▁जु\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=125302 size=1400 all=225891 active=22857 piece=ana\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=125171 min_freq=8746\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=123323 size=1420 all=227782 active=12864 piece=▁taken\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=121813 size=1440 all=229585 active=14667 piece=▁bl\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=119822 size=1460 all=232438 active=17520 piece=▁शक\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=117792 size=1480 all=234391 active=19473 piece=▁Khan\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=115809 size=1500 all=237186 active=22267 piece=इन\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=115668 min_freq=8066\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=113843 size=1520 all=239503 active=13801 piece=▁गांधी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=112132 size=1540 all=242889 active=17187 piece=▁पण\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=110881 size=1560 all=245241 active=19539 piece=▁अभि\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=108831 size=1580 all=248371 active=22669 piece=▁fin\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=106836 size=1600 all=250132 active=24430 piece=▁Re\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=106685 min_freq=7457\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=105176 size=1620 all=252870 active=15118 piece=uth\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=104493 size=1640 all=256308 active=18556 piece=जार\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=103188 size=1660 all=259527 active=21775 piece=▁here\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=101631 size=1680 all=262372 active=24620 piece=▁हों\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=100187 size=1700 all=264268 active=26516 piece=▁जिन\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=100131 min_freq=6807\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=98716 size=1720 all=266256 active=15132 piece=▁PM\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=97691 size=1740 all=267907 active=16783 piece=▁Mumbai\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=96783 size=1760 all=271010 active=19886 piece=▁just\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=95453 size=1780 all=273337 active=22213 piece=नेक\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=93501 size=1800 all=275315 active=24191 piece=ics\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=93356 min_freq=6313\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=92046 size=1820 all=277924 active=16225 piece=▁Comm\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=90685 size=1840 all=281554 active=19855 piece=बल\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=89531 size=1860 all=284980 active=23281 piece=म्म\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=88291 size=1880 all=286555 active=24856 piece=र्ण\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=86523 size=1900 all=288670 active=26971 piece=▁13\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=86490 min_freq=5819\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=85611 size=1920 all=290551 active=16272 piece=ivers\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=84767 size=1940 all=293522 active=19243 piece=लिए\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=83841 size=1960 all=296093 active=21813 piece=ज्ञान\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=82630 size=1980 all=297962 active=23682 piece=▁आयोज\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=81969 size=2000 all=300068 active=25788 piece=▁contin\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=81870 min_freq=5434\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=81069 size=2020 all=302039 active=16965 piece=▁मिळ\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=80131 size=2040 all=303406 active=18332 piece=▁partic\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=79090 size=2060 all=305009 active=19935 piece=▁char\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=78126 size=2080 all=306629 active=21555 piece=▁महारा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=77132 size=2100 all=308106 active=23031 piece=▁end\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=77068 min_freq=5200\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=76443 size=2120 all=310000 active=17234 piece=ुष\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=75712 size=2140 all=311466 active=18700 piece=▁कर्\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=75104 size=2160 all=313429 active=20662 piece=▁उत्पाद\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=74498 size=2180 all=315831 active=23064 piece=plain\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=73764 size=2200 all=318002 active=25235 piece=ूट\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=73675 min_freq=4945\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=73159 size=2220 all=320954 active=18549 piece=▁चे\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=72158 size=2240 all=322805 active=20400 piece=ages\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=71390 size=2260 all=325546 active=23141 piece=imes\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=70755 size=2280 all=328044 active=25639 piece=ived\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=70105 size=2300 all=329893 active=27488 piece=▁due\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=70095 min_freq=4673\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=69510 size=2320 all=331601 active=18201 piece=▁माल\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=69156 size=2340 all=333952 active=20552 piece=▁important\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=68102 size=2360 all=337467 active=24067 piece=▁/\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=67519 size=2380 all=339301 active=25901 piece=▁आपण\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=66925 size=2400 all=340279 active=26879 piece=शि\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=66905 min_freq=4416\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=66156 size=2420 all=342380 active=18581 piece=▁महत्व\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=65335 size=2440 all=343786 active=19987 piece=▁members\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=64567 size=2460 all=346193 active=22394 piece=मता\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=63822 size=2480 all=348393 active=24594 piece=▁हिंद\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=63391 size=2500 all=349831 active=26032 piece=▁देशों\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=63341 min_freq=4212\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=62493 size=2520 all=351053 active=18705 piece=▁area\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=62004 size=2540 all=353157 active=20809 piece=▁तौर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=61566 size=2560 all=354419 active=22071 piece=▁countries\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=60975 size=2580 all=356966 active=24618 piece=▁win\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=60366 size=2600 all=359209 active=26861 piece=▁दूर\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=60346 min_freq=4029\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=59769 size=2620 all=360794 active=19460 piece=▁candid\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=59301 size=2640 all=362705 active=21371 piece=द्धि\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=58901 size=2660 all=365942 active=24608 piece=▁जाना\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=58454 size=2680 all=367747 active=26413 piece=▁son\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=57729 size=2700 all=369193 active=27859 piece=▁across\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=57712 min_freq=3839\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=57243 size=2720 all=370954 active=20216 piece=augh\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=56840 size=2740 all=372345 active=21607 piece=ned\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=56360 size=2760 all=373677 active=22939 piece=▁अधिकारियों\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=55715 size=2780 all=374891 active=24153 piece=त्मक\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=55208 size=2800 all=376029 active=25290 piece=▁Im\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=55201 min_freq=3708\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=54684 size=2820 all=378006 active=20707 piece=ंना\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=54101 size=2840 all=379725 active=22426 piece=▁Fin\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=53513 size=2860 all=380933 active=23634 piece=▁Air\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=53131 size=2880 all=382473 active=25174 piece=▁Q\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=52717 size=2900 all=384776 active=27477 piece=▁around\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=52704 min_freq=3567\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=52408 size=2920 all=385954 active=20408 piece=▁wife\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=51929 size=2940 all=388518 active=22972 piece=▁मैंने\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=51358 size=2960 all=389743 active=24197 piece=▁particip\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=50943 size=2980 all=391708 active=26162 piece=▁tot\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=50625 size=3000 all=393258 active=27712 piece=▁करेगा\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=50613 min_freq=3430\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=50156 size=3020 all=395165 active=21544 piece=angu\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=49790 size=3040 all=396716 active=23095 piece=▁sl\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=49274 size=3060 all=399190 active=25569 piece=▁त्याला\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=48898 size=3080 all=400643 active=27022 piece=▁गयी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=48503 size=3100 all=403682 active=30061 piece=▁Day\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=48495 min_freq=3271\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=48235 size=3120 all=406061 active=22499 piece=▁सीमा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=47982 size=3140 all=406775 active=23213 piece=▁देता\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=47512 size=3160 all=408437 active=24875 piece=ंचा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=47163 size=3180 all=410990 active=27428 piece=▁event\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=46783 size=3200 all=412766 active=29204 piece=▁Son\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=46778 min_freq=3147\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=46317 size=3220 all=414328 active=22110 piece=▁मामलों\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=46051 size=3240 all=415586 active=23368 piece=▁Test\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=45734 size=3260 all=416635 active=24417 piece=▁dont\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=45316 size=3280 all=417658 active=25440 piece=wh\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=44972 size=3300 all=420423 active=28205 piece=▁पोलीस\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=44943 min_freq=3050\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=44639 size=3320 all=422453 active=23005 piece=▁camp\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=44397 size=3340 all=425365 active=25917 piece=▁फोट\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=44097 size=3360 all=427173 active=27725 piece=ference\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=43808 size=3380 all=428241 active=28793 piece=ंद्र\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=43454 size=3400 all=429444 active=29996 piece=▁निवेश\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=43450 min_freq=2940\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=43143 size=3420 all=431022 active=23017 piece=▁वहां\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=42860 size=3440 all=432657 active=24652 piece=▁सैन\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=42505 size=3460 all=434792 active=26787 piece=▁cannot\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=42130 size=3480 all=436682 active=28677 piece=oura\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=41778 size=3500 all=438904 active=30899 piece=▁बिहार\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=41775 min_freq=2820\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=41557 size=3520 all=440327 active=23329 piece=▁रस\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=41176 size=3540 all=441716 active=24718 piece=▁Bible\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=40900 size=3560 all=444213 active=27215 piece=anka\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=40655 size=3580 all=446182 active=29184 piece=उन\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=40414 size=3600 all=448316 active=31318 piece=▁जल्द\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=40393 min_freq=2720\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=40223 size=3620 all=449807 active=23897 piece=▁बेहतर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=40010 size=3640 all=451741 active=25831 piece=▁शेयर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=39789 size=3660 all=453379 active=27469 piece=ps\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=39540 size=3680 all=454550 active=28640 piece=▁Supreme\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=39227 size=3700 all=456701 active=30791 piece=▁rul\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=39219 min_freq=2627\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=39001 size=3720 all=458563 active=24684 piece=▁बंगाल\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38674 size=3740 all=460528 active=26649 piece=▁dev\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38497 size=3760 all=462959 active=29080 piece=uture\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38314 size=3780 all=465769 active=31890 piece=ंनी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38065 size=3800 all=467925 active=34046 piece=▁Both\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=38050 min_freq=2514\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=37854 size=3820 all=469602 active=25061 piece=▁CM\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=37665 size=3840 all=470618 active=26077 piece=ivil\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=37383 size=3860 all=473336 active=28795 piece=▁छोट\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=37180 size=3880 all=474795 active=30254 piece=▁गोष्ट\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=36993 size=3900 all=476910 active=32369 piece=▁तुल\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=36973 min_freq=2435\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=36779 size=3920 all=478605 active=25485 piece=ंज\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=36485 size=3940 all=480232 active=27112 piece=स्ती\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=36168 size=3960 all=481693 active=28573 piece=▁applic\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=35919 size=3980 all=483618 active=30498 piece=▁मॉ\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=35739 size=4000 all=486254 active=33134 piece=arents\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=35738 min_freq=2348\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=35435 size=4020 all=488032 active=26083 piece=▁खबर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=35205 size=4040 all=490260 active=28311 piece=ude\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=35037 size=4060 all=491831 active=29882 piece=ानीय\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34875 size=4080 all=493621 active=31672 piece=▁ज़ि\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34617 size=4100 all=495576 active=33627 piece=▁pict\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=34616 min_freq=2269\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34371 size=4120 all=497211 active=26405 piece=र्ती\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34187 size=4140 all=499484 active=28678 piece=वली\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=33979 size=4160 all=502429 active=31623 piece=era\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=33853 size=4180 all=504434 active=33628 piece=rug\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=33555 size=4200 all=506221 active=35415 piece=▁तेव्हा\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=33553 min_freq=2184\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=33380 size=4220 all=508475 active=27539 piece=ेंड\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=33218 size=4240 all=510079 active=29143 piece=▁2014\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=33050 size=4260 all=511436 active=30500 piece=▁इतर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32851 size=4280 all=513105 active=32169 piece=ert\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32587 size=4300 all=515634 active=34698 piece=ained\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=32578 min_freq=2114\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32457 size=4320 all=516934 active=27038 piece=▁एफ\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32204 size=4340 all=518686 active=28790 piece=▁Finance\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32058 size=4360 all=520525 active=30629 piece=▁हाद\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=31880 size=4380 all=521503 active=31607 piece=▁वही\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=31760 size=4400 all=522662 active=32766 piece=icles\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=31748 min_freq=2059\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=31589 size=4420 all=524166 active=27597 piece=▁Tha\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=31446 size=4440 all=525369 active=28800 piece=ेन\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=31292 size=4460 all=526493 active=29924 piece=िए\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=31075 size=4480 all=529612 active=33043 piece=उस\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30871 size=4500 all=532953 active=36384 piece=टना\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=30869 min_freq=1988\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30713 size=4520 all=534415 active=27917 piece=▁getting\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30500 size=4540 all=535783 active=29285 piece=▁समु\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30216 size=4560 all=537945 active=31447 piece=▁travel\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30039 size=4580 all=539220 active=32722 piece=▁इतिहास\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29875 size=4600 all=540573 active=34075 piece=▁benefit\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=29862 min_freq=1939\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29718 size=4620 all=541735 active=28179 piece=▁नोट\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29599 size=4640 all=543173 active=29617 piece=isions\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29415 size=4660 all=544898 active=31342 piece=पत्र\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29246 size=4680 all=546655 active=33099 piece=ung\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29081 size=4700 all=548725 active=35169 piece=witter\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=29079 min_freq=1889\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28888 size=4720 all=550443 active=29137 piece=▁सलमान\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28728 size=4740 all=552517 active=31211 piece=▁शेत\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28625 size=4760 all=554382 active=33076 piece=▁सूची\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28443 size=4780 all=556232 active=34926 piece=▁सत\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28335 size=4800 all=557576 active=36269 piece=itor\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=28327 min_freq=1835\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28216 size=4820 all=559455 active=29676 piece=ains\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28019 size=4840 all=562356 active=32577 piece=▁trib\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27913 size=4860 all=563802 active=34023 piece=▁जीव\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27798 size=4880 all=565078 active=35299 piece=▁फिलहाल\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27577 size=4900 all=567358 active=37579 piece=▁घोषित\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=27569 min_freq=1779\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27408 size=4920 all=569070 active=30069 piece=▁म्हट\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27313 size=4940 all=570088 active=31087 piece=iah\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27185 size=4960 all=572028 active=33027 piece=▁यांना\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27005 size=4980 all=572983 active=33982 piece=▁कल्या\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26810 size=5000 all=574331 active=35330 piece=▁केन्द्र\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=26808 min_freq=1735\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26675 size=5020 all=576045 active=30359 piece=▁त्र\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26547 size=5040 all=578137 active=32451 piece=In\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26339 size=5060 all=579786 active=34100 piece=cri\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26186 size=5080 all=581053 active=35367 piece=▁समावेश\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26068 size=5100 all=583224 active=37538 piece=▁हवाई\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=26062 min_freq=1689\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25960 size=5120 all=584930 active=30827 piece=▁माजी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25843 size=5140 all=587296 active=33193 piece=ilt\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25671 size=5160 all=588888 active=34785 piece=▁विदेशी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25565 size=5180 all=590064 active=35961 piece=lu\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25414 size=5200 all=592022 active=37919 piece=श्विक\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=25408 min_freq=1642\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25292 size=5220 all=593261 active=30817 piece=▁नवा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25196 size=5240 all=595579 active=33135 piece=▁आध\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25049 size=5260 all=596704 active=34260 piece=▁king\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24894 size=5280 all=598072 active=35628 piece=▁viral\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24759 size=5300 all=599306 active=36862 piece=▁results\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=24752 min_freq=1606\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24669 size=5320 all=600696 active=31347 piece=mi\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24550 size=5340 all=602239 active=32890 piece=▁निदेशक\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24424 size=5360 all=603430 active=34081 piece=▁central\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24286 size=5380 all=604424 active=35075 piece=oved\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24157 size=5400 all=605765 active=36416 piece=ream\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=24157 min_freq=1570\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24065 size=5420 all=606881 active=31330 piece=▁emer\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23948 size=5440 all=608330 active=32779 piece=▁Dav\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23831 size=5460 all=609760 active=34208 piece=▁चंद्र\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23736 size=5480 all=611828 active=36276 piece=वालों\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23619 size=5500 all=613092 active=37540 piece=▁Art\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=23618 min_freq=1538\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23514 size=5520 all=615163 active=32661 piece=▁संवाद\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23408 size=5540 all=617115 active=34613 piece=▁500\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23321 size=5560 all=618020 active=35518 piece=▁भागी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23177 size=5580 all=619483 active=36981 piece=▁suggest\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23045 size=5600 all=621166 active=38664 piece=▁खंड\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=23039 min_freq=1501\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22944 size=5620 all=622913 active=32699 piece=▁Priyanka\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22838 size=5640 all=624080 active=33866 piece=▁More\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22753 size=5660 all=625322 active=35108 piece=▁परवरदिगार\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22656 size=5680 all=627247 active=37033 piece=ns\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22573 size=5700 all=628872 active=38658 piece=िप्\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=22573 min_freq=1467\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22472 size=5720 all=630528 active=32982 piece=▁वेबसाइट\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22393 size=5740 all=631552 active=34006 piece=▁song\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22290 size=5760 all=633375 active=35829 piece=▁reject\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22191 size=5780 all=634731 active=37185 piece=▁allowed\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22100 size=5800 all=635805 active=38259 piece=▁webs\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=22099 min_freq=1438\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21987 size=5820 all=636394 active=32374 piece=▁टै\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21890 size=5840 all=637474 active=33454 piece=▁whether\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21802 size=5860 all=638471 active=34451 piece=▁i\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21729 size=5880 all=639527 active=35507 piece=▁create\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21649 size=5900 all=640081 active=36061 piece=▁370\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=21646 min_freq=1417\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21581 size=5920 all=642141 active=34024 piece=दराबाद\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21461 size=5940 all=643160 active=35043 piece=▁असम\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21378 size=5960 all=644163 active=36046 piece=नो\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21290 size=5980 all=646012 active=37895 piece=atic\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21231 size=6000 all=647422 active=39305 piece=▁letter\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=21227 min_freq=1387\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21155 size=6020 all=648389 active=33328 piece=quir\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21039 size=6040 all=650299 active=35238 piece=▁स्वागत\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20962 size=6060 all=651217 active=36156 piece=▁हालत\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20858 size=6080 all=652852 active=37791 piece=▁English\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20777 size=6100 all=653996 active=38935 piece=▁needed\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=20776 min_freq=1361\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20706 size=6120 all=655207 active=33907 piece=▁hol\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20615 size=6140 all=656561 active=35261 piece=DP\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20545 size=6160 all=657804 active=36504 piece=▁जाये\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20433 size=6180 all=658785 active=37485 piece=▁येश\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20340 size=6200 all=659887 active=38587 piece=▁याचा\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=20335 min_freq=1338\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20253 size=6220 all=660691 active=33791 piece=▁बनने\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20079 size=6240 all=661823 active=34923 piece=▁constituency\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20022 size=6260 all=662731 active=35831 piece=▁Kejri\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19957 size=6280 all=663920 active=37020 piece=DA\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19871 size=6300 all=665181 active=38281 piece=ene\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=19871 min_freq=1317\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19782 size=6320 all=665992 active=33881 piece=▁includes\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19687 size=6340 all=667537 active=35426 piece=▁अमरी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19618 size=6360 all=668370 active=36259 piece=▁)\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19563 size=6380 all=670401 active=38290 piece=▁तुर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19472 size=6400 all=671517 active=39406 piece=▁Constitution\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=19465 min_freq=1292\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19390 size=6420 all=672927 active=34980 piece=▁मिलेगी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19298 size=6440 all=674530 active=36583 piece=▁ways\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19226 size=6460 all=675186 active=37239 piece=▁protect\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19168 size=6480 all=676571 active=38624 piece=▁मारे\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19089 size=6500 all=677518 active=39571 piece=eel\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=19086 min_freq=1272\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19009 size=6520 all=678557 active=34805 piece=▁prior\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18911 size=6540 all=680283 active=36531 piece=▁राजधानी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18825 size=6560 all=681160 active=37408 piece=▁Besides\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18752 size=6580 all=681986 active=38234 piece=▁सश\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18667 size=6600 all=683561 active=39809 piece=▁स्टेशन\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=18666 min_freq=1251\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18603 size=6620 all=685450 active=36011 piece=▁everything\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18521 size=6640 all=687122 active=37683 piece=▁Special\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18446 size=6660 all=689076 active=39637 piece=jun\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18372 size=6680 all=690501 active=41062 piece=▁चोट\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18315 size=6700 all=691874 active=42435 piece=ांवर\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=18314 min_freq=1222\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18250 size=6720 all=693777 active=36112 piece=▁मल\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18189 size=6740 all=694875 active=37210 piece=दारों\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18108 size=6760 all=696007 active=38342 piece=▁houses\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18036 size=6780 all=696546 active=38881 piece=▁shar\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17970 size=6800 all=698064 active=40399 piece=ript\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=17968 min_freq=1202\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17908 size=6820 all=699403 active=36202 piece=▁changes\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17835 size=6840 all=700729 active=37528 piece=▁स्वतः\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17759 size=6860 all=702192 active=38991 piece=▁ऋण\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17687 size=6880 all=703345 active=40144 piece=ताव\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17597 size=6900 all=705005 active=41804 piece=▁Ben\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=17595 min_freq=1180\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17529 size=6920 all=706079 active=36214 piece=▁प्री\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17460 size=6940 all=706983 active=37118 piece=▁बें\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17407 size=6960 all=708655 active=38790 piece=▁respond\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17298 size=6980 all=709948 active=40083 piece=▁चले\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17189 size=7000 all=710879 active=41014 piece=▁अंदर\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=17189 min_freq=1161\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17138 size=7020 all=712213 active=36845 piece=▁employment\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17019 size=7040 all=713352 active=37984 piece=ique\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16962 size=7060 all=714174 active=38806 piece=▁कोच\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16912 size=7080 all=715463 active=40095 piece=▁प्रावधान\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16851 size=7100 all=716886 active=41518 piece=बो\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16851 min_freq=1141\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16799 size=7120 all=718658 active=36951 piece=ruit\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16731 size=7140 all=719900 active=38193 piece=▁गेल्या\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16663 size=7160 all=721762 active=40055 piece=rew\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16604 size=7180 all=722865 active=41158 piece=▁दहशत\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16555 size=7200 all=723786 active=42079 piece=▁examination\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16551 min_freq=1124\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16488 size=7220 all=724666 active=37068 piece=▁participated\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16434 size=7240 all=725828 active=38230 piece=▁मोठा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16373 size=7260 all=727272 active=39674 piece=▁Zealand\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16319 size=7280 all=728002 active=40404 piece=▁मुझ\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16267 size=7300 all=729430 active=41832 piece=▁round\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16261 min_freq=1105\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16182 size=7320 all=730394 active=37420 piece=2,\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16115 size=7340 all=731497 active=38523 piece=▁judge\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16040 size=7360 all=732867 active=39893 piece=▁Tal\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15995 size=7380 all=734156 active=41182 piece=▁नायडू\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15960 size=7400 all=735291 active=42317 piece=▁explain\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=15958 min_freq=1088\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15906 size=7420 all=736398 active=37864 piece=▁सामग्री\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15840 size=7440 all=737513 active=38979 piece=▁surv\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15771 size=7460 all=738208 active=39674 piece=▁पदार्थ\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15713 size=7480 all=738942 active=40408 piece=▁आयुष\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15640 size=7500 all=740240 active=41706 piece=▁कोणी\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=15639 min_freq=1074\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15583 size=7520 all=741785 active=38532 piece=▁challenges\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15545 size=7540 all=742320 active=39067 piece=▁hearing\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15510 size=7560 all=743378 active=40125 piece=▁तिला\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15432 size=7580 all=744123 active=40870 piece=▁विस्\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15367 size=7600 all=745810 active=42557 piece=IP\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=15366 min_freq=1058\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15326 size=7620 all=746484 active=37828 piece=▁गड\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15264 size=7640 all=747098 active=38442 piece=▁benefits\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15214 size=7660 all=748265 active=39609 piece=▁अनुरोध\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15159 size=7680 all=749446 active=40790 piece=▁नही\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15102 size=7700 all=750833 active=42177 piece=▁वातावरण\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=15097 min_freq=1043\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15034 size=7720 all=751647 active=38327 piece=hai\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14992 size=7740 all=753257 active=39937 piece=▁शकत\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14944 size=7760 all=753914 active=40594 piece=दाता\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14889 size=7780 all=755139 active=41819 piece=▁वेस्ट\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14805 size=7800 all=756481 active=43161 piece=▁Tour\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=14801 min_freq=1028\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14745 size=7820 all=757625 active=38951 piece=▁पंजी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14702 size=7840 all=758806 active=40132 piece=▁साह\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14640 size=7860 all=760201 active=41527 piece=▁recorded\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14605 size=7880 all=761365 active=42691 piece=▁spokesperson\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14581 size=7900 all=762801 active=44127 piece=▁Gupt\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=14581 min_freq=1011\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14532 size=7920 all=763965 active=39286 piece=▁समुद्र\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14478 size=7940 all=765313 active=40634 piece=आईटी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14439 size=7960 all=766497 active=41818 piece=▁risk\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14392 size=7980 all=767735 active=43056 piece=तीश\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14357 size=8000 all=768731 active=44052 piece=de\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=14357 min_freq=994\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14312 size=8020 all=770976 active=40365 piece=▁खिलाड़ियों\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14254 size=8040 all=771873 active=41262 piece=5,\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14216 size=8060 all=772878 active=42267 piece=▁Lim\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14161 size=8080 all=774330 active=43719 piece=▁Hence\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14118 size=8100 all=774982 active=44371 piece=ार्द\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=14118 min_freq=979\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14074 size=8120 all=776124 active=39823 piece=oper\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14041 size=8140 all=777345 active=41044 piece=▁numbers\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13992 size=8160 all=779388 active=43087 piece=▁lay\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13937 size=8180 all=780454 active=44153 piece=▁rains\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13898 size=8200 all=781303 active=45002 piece=▁sle\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=13896 min_freq=962\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13838 size=8220 all=781760 active=39508 piece=▁होत्या\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13797 size=8240 all=782883 active=40631 piece=akhand\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13755 size=8260 all=784194 active=41942 piece=ण्याच्या\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13728 size=8280 all=785017 active=42765 piece=र्द\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13696 size=8300 all=786682 active=44430 piece=▁डायरे\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=13692 min_freq=949\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13632 size=8320 all=790045 active=42684 piece=▁evening\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13564 size=8340 all=791010 active=43649 piece=▁अर्जुन\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13515 size=8360 all=791771 active=44410 piece=▁मीडियावर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13474 size=8380 all=792850 active=45489 piece=▁network\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13433 size=8400 all=794254 active=46893 piece=▁हिमाचल\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=13428 min_freq=934\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13376 size=8420 all=795134 active=40575 piece=▁ordered\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13330 size=8440 all=795798 active=41239 piece=▁अब्द\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13291 size=8460 all=796872 active=42313 piece=▁Economic\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13239 size=8480 all=797537 active=42978 piece=.,\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13200 size=8500 all=798652 active=44093 piece=▁होनी\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=13199 min_freq=923\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13162 size=8520 all=799484 active=40763 piece=फाई\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13115 size=8540 all=800861 active=42140 piece=▁दृष्टि\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13081 size=8560 all=802241 active=43520 piece=▁photo\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13055 size=8580 all=803233 active=44512 piece=▁systems\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13018 size=8600 all=804143 active=45422 piece=▁अभिष\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=13018 min_freq=910\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12971 size=8620 all=805488 active=41539 piece=▁avoid\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12934 size=8640 all=806255 active=42306 piece=रावट\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12901 size=8660 all=807485 active=43536 piece=▁fem\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12869 size=8680 all=808246 active=44297 piece=▁equal\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12821 size=8700 all=809344 active=45395 piece=va\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=12819 min_freq=897\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12786 size=8720 all=810377 active=41215 piece=▁Jait\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12745 size=8740 all=811867 active=42705 piece=▁Port\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12702 size=8760 all=813144 active=43982 piece=▁Transport\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12647 size=8780 all=813864 active=44702 piece=▁तैयारी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12596 size=8800 all=814599 active=45437 piece=ढ़ी\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=12592 min_freq=886\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12541 size=8820 all=816128 active=42127 piece=▁आएंगे\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12478 size=8840 all=816693 active=42692 piece=▁लोकतंत्र\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12424 size=8860 all=817418 active=43417 piece=▁note\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12366 size=8880 all=818381 active=44380 piece=▁plea\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12316 size=8900 all=819837 active=45836 piece=▁hearts\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=12312 min_freq=873\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12283 size=8920 all=821165 active=42317 piece=▁ताब्यात\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12236 size=8940 all=822279 active=43431 piece=▁55\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12195 size=8960 all=823281 active=44433 piece=▁एह\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12149 size=8980 all=824209 active=45361 piece=▁स्थल\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12115 size=9000 all=825625 active=46777 piece=hal\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=12114 min_freq=860\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12087 size=9020 all=827580 active=42919 piece=set\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12050 size=9040 all=829336 active=44675 piece=▁Bharatiya\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12009 size=9060 all=829868 active=45207 piece=▁वनडे\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11974 size=9080 all=830252 active=45591 piece=ड्या\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11943 size=9100 all=832143 active=47482 piece=oples\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11943 min_freq=847\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11911 size=9120 all=833149 active=42609 piece=दायक\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11872 size=9140 all=834205 active=43665 piece=थर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11829 size=9160 all=836061 active=45521 piece=▁virus\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11802 size=9180 all=837296 active=46756 piece=▁Adityanath\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11768 size=9200 all=837806 active=47266 piece=▁units\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11767 min_freq=836\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11738 size=9220 all=838891 active=42968 piece=▁सूच\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11704 size=9240 all=839732 active=43809 piece=▁Karan\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11653 size=9260 all=841117 active=45194 piece=80\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11611 size=9280 all=842050 active=46127 piece=▁बुद्धि\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11586 size=9300 all=843390 active=47467 piece=CB\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11582 min_freq=825\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11553 size=9320 all=844258 active=42940 piece=कस\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11512 size=9340 all=844957 active=43639 piece=’’\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11473 size=9360 all=846013 active=44695 piece=▁उपाध्यक्ष\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11425 size=9380 all=847419 active=46101 piece=▁payment\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11391 size=9400 all=847957 active=46639 piece=▁शुरूआत\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11390 min_freq=816\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11357 size=9420 all=848748 active=43182 piece=▁नेहमी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11331 size=9440 all=849701 active=44135 piece=कर्ताओं\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11307 size=9460 all=850939 active=45373 piece=▁मोटर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11261 size=9480 all=851974 active=46408 piece=▁2017-18\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11231 size=9500 all=854261 active=48695 piece=▁CR\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11226 min_freq=803\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11198 size=9520 all=855188 active=43598 piece=icate\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11146 size=9540 all=856956 active=45366 piece=ashing\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11120 size=9560 all=858082 active=46492 piece=▁strike\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11098 size=9580 all=858950 active=47360 piece=▁America\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11063 size=9600 all=859627 active=48037 piece=▁मज़\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11061 min_freq=792\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11027 size=9620 all=860837 active=44146 piece=▁incidents\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10993 size=9640 all=862227 active=45536 piece=्डी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10960 size=9660 all=862988 active=46297 piece=▁नयी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10931 size=9680 all=864201 active=47510 piece=▁दिसंबर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10883 size=9700 all=864676 active=47985 piece=▁Lead\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10880 min_freq=783\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10857 size=9720 all=865515 active=44063 piece=▁होंगी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10835 size=9740 all=866504 active=45052 piece=riving\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10807 size=9760 all=867280 active=45828 piece=▁Rad\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10777 size=9780 all=868418 active=46966 piece=▁SA\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10742 size=9800 all=871021 active=49569 piece=घ्र\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10737 min_freq=773\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10694 size=9820 all=872460 active=44924 piece=▁ओल\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10664 size=9840 all=873524 active=45988 piece=स्थे\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10632 size=9860 all=874499 active=46963 piece=▁announcement\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10607 size=9880 all=875558 active=48022 piece=प्पा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10579 size=9900 all=877388 active=49852 piece=iction\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10579 min_freq=763\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10557 size=9920 all=878237 active=44669 piece=aman\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10520 size=9940 all=879225 active=45657 piece=▁साझेदारी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10502 size=9960 all=880315 active=46747 piece=▁समोर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10475 size=9980 all=881729 active=48161 piece=▁carrying\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10451 size=10000 all=882528 active=48960 piece=▁Business\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10451 min_freq=755\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10424 size=10020 all=883410 active=44989 piece=▁पांडे\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10399 size=10040 all=884459 active=46038 piece=▁sun\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10373 size=10060 all=885529 active=47108 piece=▁tourism\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10339 size=10080 all=886444 active=48023 piece=▁जोखिम\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10307 size=10100 all=888217 active=49796 piece=araman\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10306 min_freq=745\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10264 size=10120 all=889344 active=45491 piece=▁शेष\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10236 size=10140 all=890241 active=46388 piece=र्चा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10197 size=10160 all=891071 active=47218 piece=▁अक्टूबर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10178 size=10180 all=891791 active=47938 piece=akers\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10158 size=10200 all=892461 active=48608 piece=iment\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10157 min_freq=737\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10115 size=10220 all=893137 active=45224 piece=▁बनाकर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10090 size=10240 all=894425 active=46512 piece=.”\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10052 size=10260 all=895404 active=47491 piece=▁Mamata\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10027 size=10280 all=896256 active=48343 piece=''\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10008 size=10300 all=896873 active=48960 piece=▁अधिव\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10007 min_freq=730\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9978 size=10320 all=897572 active=45517 piece=्रास\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9956 size=10340 all=898246 active=46191 piece=lease\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9943 size=10360 all=898840 active=46785 piece=▁गिरफ्तारी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9913 size=10380 all=899217 active=47162 piece=▁फ़िल्म\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9889 size=10400 all=900363 active=48308 piece=▁Rai\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9888 min_freq=723\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9861 size=10420 all=901031 active=45669 piece=▁करायला\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9829 size=10440 all=901794 active=46432 piece=▁रिजर्व\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9802 size=10460 all=902962 active=47600 piece=▁faithful\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9782 size=10480 all=903837 active=48475 piece=▁feet\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9752 size=10500 all=904566 active=49204 piece=▁डाउन\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9751 min_freq=715\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9726 size=10520 all=906210 active=46833 piece=त्तर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9700 size=10540 all=907312 active=47935 piece=▁polic\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9675 size=10560 all=908350 active=48973 piece=▁mankind\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9653 size=10580 all=909855 active=50478 piece=adium\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9631 size=10600 all=911265 active=51888 piece=oli\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9630 min_freq=704\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9614 size=10620 all=912459 active=46514 piece=हारी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9593 size=10640 all=913920 active=47975 piece=▁medal\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9572 size=10660 all=914965 active=49020 piece=▁सौं\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9527 size=10680 all=916015 active=50070 piece=▁ED\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9491 size=10700 all=916690 active=50745 piece=megapixel\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9490 min_freq=696\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9469 size=10720 all=917516 active=46661 piece=णारा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9435 size=10740 all=918184 active=47329 piece=▁Suresh\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9404 size=10760 all=918942 active=48087 piece=▁देशातील\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9378 size=10780 all=919755 active=48900 piece=▁कदा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9360 size=10800 all=921177 active=50322 piece=▁Goyal\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9358 min_freq=690\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9330 size=10820 all=922253 active=47108 piece=▁धावा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9303 size=10840 all=923819 active=48674 piece=▁guard\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9273 size=10860 all=924550 active=49405 piece=▁Lo\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9252 size=10880 all=925511 active=50366 piece=▁समूहों\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9231 size=10900 all=926171 active=51026 piece=▁videos\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9229 min_freq=684\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9203 size=10920 all=928069 active=48206 piece=▁पराम\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9183 size=10940 all=928551 active=48688 piece=णीय\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9153 size=10960 all=929598 active=49735 piece=asp\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9127 size=10980 all=930862 active=50999 piece=▁प्रतिस्पर्\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9099 size=11000 all=931778 active=51915 piece=▁मुहैया\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9098 min_freq=675\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9075 size=11020 all=932549 active=47359 piece=▁संसार\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9041 size=11040 all=933189 active=47999 piece=भाषा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9012 size=11060 all=934439 active=49249 piece=▁size\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8992 size=11080 all=935354 active=50164 piece=▁घुस\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8964 size=11100 all=936221 active=51031 piece=▁मानवी\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8963 min_freq=669\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8929 size=11120 all=937404 active=47981 piece=▁हालाँकि\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8907 size=11140 all=939025 active=49602 piece=ilty\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8887 size=11160 all=940011 active=50588 piece=sp\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8860 size=11180 all=940673 active=51250 piece=▁deeds\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8839 size=11200 all=941676 active=52253 piece=आधी\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8837 min_freq=661\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8808 size=11220 all=942944 active=48173 piece=▁stood\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8795 size=11240 all=944497 active=49726 piece=▁original\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8772 size=11260 all=945786 active=51014 piece=▁कामगार\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8752 size=11280 all=946247 active=51475 piece=▁Ramesh\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8723 size=11300 all=947034 active=52262 piece=▁काँग्रेसचे\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8722 min_freq=654\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8697 size=11320 all=948022 active=48335 piece=▁मुख्यालय\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8676 size=11340 all=948639 active=48952 piece=धानिक\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8653 size=11360 all=949164 active=49477 piece=▁स्वर्ण\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8633 size=11380 all=950419 active=50732 piece=▁नाज़िल\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8618 size=11400 all=950880 active=51193 piece=कर्मियों\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8617 min_freq=648\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8591 size=11420 all=951688 active=48233 piece=▁इट\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8570 size=11440 all=952612 active=49157 piece=▁Saf\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8547 size=11460 all=953720 active=50265 piece=▁Sara\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8533 size=11480 all=954818 active=51363 piece=▁organization\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8505 size=11500 all=956072 active=52617 piece=ब्लिक\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8504 min_freq=640\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8483 size=11520 all=956751 active=48436 piece=▁overse\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8455 size=11540 all=957816 active=49501 piece=▁connected\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8435 size=11560 all=959060 active=50745 piece=▁युग\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8417 size=11580 all=959880 active=51565 piece=▁diss\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8398 size=11600 all=960822 active=52507 piece=▁जमानत\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8397 min_freq=633\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8379 size=11620 all=961779 active=48993 piece=▁मलिक\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8358 size=11640 all=962318 active=49532 piece=▁historic\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8341 size=11660 all=962886 active=50100 piece=▁Speaker\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8320 size=11680 all=964033 active=51247 piece=माग\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8298 size=11700 all=964723 active=51937 piece=▁fifth\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8298 min_freq=628\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8271 size=11720 all=965629 active=49141 piece=▁व्हिडीओ\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8249 size=11740 all=966403 active=49915 piece=▁मणिप\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8232 size=11760 all=967228 active=50740 piece=▁योज\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8207 size=11780 all=968520 active=52032 piece=▁Ste\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8194 size=11800 all=969186 active=52698 piece=डीएस\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8194 min_freq=621\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8181 size=11820 all=969848 active=48994 piece=▁Earth\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8160 size=11840 all=970760 active=49906 piece=▁नव्या\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8139 size=11860 all=971395 active=50541 piece=पालिका\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8121 size=11880 all=971996 active=51142 piece=▁59\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8102 size=11900 all=973973 active=53119 piece=▁शिवा\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8101 min_freq=615\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8074 size=11920 all=974696 active=49351 piece=आईएस\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8051 size=11940 all=976191 active=50846 piece=▁stre\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8030 size=11960 all=977470 active=52125 piece=▁Temple\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8008 size=11980 all=978812 active=53467 piece=▁trees\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7987 size=12000 all=979326 active=53981 piece=▁loving\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7986 min_freq=609\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7968 size=12020 all=980287 active=49926 piece=▁planned\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7951 size=12040 all=980717 active=50356 piece=काने\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7935 size=12060 all=981564 active=51203 piece=▁हटाने\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7915 size=12080 all=982584 active=52223 piece=▁union\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7899 size=12100 all=982946 active=52585 piece=hans\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7899 min_freq=604\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7876 size=12120 all=983706 active=49791 piece=▁Prom\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7850 size=12140 all=984465 active=50550 piece=ोसी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7826 size=12160 all=985499 active=51584 piece=▁कायदा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7810 size=12180 all=986549 active=52634 piece=▁घटक\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7790 size=12200 all=987849 active=53934 piece=ंसक\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7790 min_freq=598\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7773 size=12220 all=988634 active=50138 piece=RE\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7759 size=12240 all=989869 active=51373 piece=ेंगी\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7743 size=12260 all=990880 active=52384 piece=▁संग्रहण\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7725 size=12280 all=992340 active=53844 piece=▁इकट\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7709 size=12300 all=993356 active=54860 piece=ढी\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7708 min_freq=591\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7690 size=12320 all=994764 active=50871 piece=▁ढांचा\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7675 size=12340 all=995348 active=51455 piece=▁प्रतिबद्धता\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7656 size=12360 all=996250 active=52357 piece=▁struggle\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7641 size=12380 all=996963 active=53070 piece=▁strongly\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7626 size=12400 all=997755 active=53862 piece=▁Ba\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7624 min_freq=585\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7614 size=12420 all=999106 active=51104 piece=▁association\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7596 size=12440 all=999578 active=51576 piece=▁investigations\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7576 size=12460 all=1000401 active=52399 piece=▁क्रमश\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7560 size=12480 all=1001324 active=53322 piece=याचे\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7549 size=12500 all=1002370 active=54368 piece=▁सामर्थ\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7548 min_freq=580\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7540 size=12520 all=1003216 active=50939 piece=▁CAA\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7528 size=12540 all=1004223 active=51946 piece=▁असली\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7515 size=12560 all=1004801 active=52524 piece=▁proved\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7498 size=12580 all=1005652 active=53375 piece=▁सतर्क\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7479 size=12600 all=1006386 active=54109 piece=ोजित\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7479 min_freq=575\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7452 size=12620 all=1007167 active=51061 piece=▁२००\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7437 size=12640 all=1007705 active=51599 piece=▁मॉड\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7422 size=12660 all=1009802 active=53696 piece=▁67\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7411 size=12680 all=1011488 active=55382 piece=▁शैली\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7386 size=12700 all=1012863 active=56757 piece=▁गुंतव\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7385 min_freq=568\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7363 size=12720 all=1013562 active=51322 piece=▁emergency\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7344 size=12740 all=1015061 active=52821 piece=▁सूक्ष्म\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7329 size=12760 all=1015947 active=53707 piece=▁magn\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7309 size=12780 all=1016738 active=54498 piece=▁कर्त\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7285 size=12800 all=1017507 active=55267 piece=▁helping\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7280 min_freq=563\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7267 size=12820 all=1018290 active=51657 piece=मंद\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7253 size=12840 all=1019160 active=52527 piece=▁quickly\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7242 size=12860 all=1019863 active=53230 piece=▁विश्लेषण\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7229 size=12880 all=1020722 active=54089 piece=▁रिसर्च\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7211 size=12900 all=1021816 active=55183 piece=▁thoughts\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7210 min_freq=558\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7190 size=12920 all=1022656 active=51930 piece=▁माया\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7175 size=12940 all=1023493 active=52767 piece=▁प्रस्\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7160 size=12960 all=1024737 active=54011 piece=casting\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7145 size=12980 all=1025486 active=54760 piece=संदेह\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7129 size=13000 all=1026878 active=56152 piece=▁Amendment\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7128 min_freq=552\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7104 size=13020 all=1027567 active=52032 piece=▁animal\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7086 size=13040 all=1028102 active=52567 piece=▁Sir\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7061 size=13060 all=1029034 active=53499 piece=razil\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7053 size=13080 all=1029833 active=54298 piece=amental\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7045 size=13100 all=1030489 active=54954 piece=▁प्लान\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7044 min_freq=548\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7031 size=13120 all=1031832 active=52826 piece=▁बचत\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7015 size=13140 all=1032511 active=53505 piece=▁शुरु\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7000 size=13160 all=1033207 active=54201 piece=▁लाइसेंस\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6981 size=13180 all=1034580 active=55574 piece=▁theme\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6967 size=13200 all=1035700 active=56694 piece=▁repeated\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6967 min_freq=542\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6954 size=13220 all=1036193 active=52277 piece=▁Cooperation\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6931 size=13240 all=1036760 active=52844 piece=▁देखिए\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6918 size=13260 all=1037502 active=53586 piece=▁ST\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6904 size=13280 all=1038223 active=54307 piece=क्चर\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6892 size=13300 all=1040320 active=56404 piece=▁Press\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6891 min_freq=537\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6876 size=13320 all=1041155 active=52829 piece=▁territory\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6864 size=13340 all=1042119 active=53793 piece=▁मूल्यांकन\n",
            "trainer_interface.cc(615) LOG(INFO) Saving model: ./mr_hi.en.bpe16k/sentencepiece.bpe.model\n",
            "trainer_interface.cc(626) LOG(INFO) Saving vocabs: ./mr_hi.en.bpe16k/sentencepiece.bpe.vocab\n",
            "encoding train with learned BPE...\n",
            "processed 10000 lines\n",
            "processed 20000 lines\n",
            "processed 30000 lines\n",
            "processed 40000 lines\n",
            "processed 50000 lines\n",
            "processed 60000 lines\n",
            "processed 70000 lines\n",
            "processed 80000 lines\n",
            "processed 90000 lines\n",
            "processed 100000 lines\n",
            "processed 110000 lines\n",
            "processed 120000 lines\n",
            "processed 130000 lines\n",
            "processed 140000 lines\n",
            "processed 150000 lines\n",
            "processed 160000 lines\n",
            "processed 170000 lines\n",
            "processed 180000 lines\n",
            "processed 190000 lines\n",
            "processed 200000 lines\n",
            "processed 210000 lines\n",
            "processed 220000 lines\n",
            "processed 230000 lines\n",
            "processed 240000 lines\n",
            "processed 250000 lines\n",
            "processed 260000 lines\n",
            "processed 270000 lines\n",
            "processed 280000 lines\n",
            "processed 290000 lines\n",
            "processed 300000 lines\n",
            "processed 310000 lines\n",
            "processed 320000 lines\n",
            "processed 330000 lines\n",
            "processed 340000 lines\n",
            "processed 350000 lines\n",
            "processed 360000 lines\n",
            "processed 370000 lines\n",
            "processed 380000 lines\n",
            "processed 390000 lines\n",
            "processed 400000 lines\n",
            "processed 410000 lines\n",
            "processed 420000 lines\n",
            "processed 430000 lines\n",
            "processed 440000 lines\n",
            "processed 450000 lines\n",
            "processed 460000 lines\n",
            "processed 470000 lines\n",
            "processed 480000 lines\n",
            "processed 490000 lines\n",
            "processed 500000 lines\n",
            "processed 510000 lines\n",
            "processed 520000 lines\n",
            "processed 530000 lines\n",
            "processed 540000 lines\n",
            "processed 550000 lines\n",
            "processed 560000 lines\n",
            "processed 570000 lines\n",
            "processed 580000 lines\n",
            "processed 590000 lines\n",
            "processed 600000 lines\n",
            "processed 610000 lines\n",
            "processed 620000 lines\n",
            "processed 630000 lines\n",
            "processed 640000 lines\n",
            "processed 650000 lines\n",
            "processed 660000 lines\n",
            "processed 670000 lines\n",
            "processed 680000 lines\n",
            "processed 690000 lines\n",
            "processed 700000 lines\n",
            "processed 710000 lines\n",
            "processed 720000 lines\n",
            "processed 730000 lines\n",
            "processed 740000 lines\n",
            "processed 750000 lines\n",
            "processed 760000 lines\n",
            "processed 770000 lines\n",
            "processed 780000 lines\n",
            "processed 790000 lines\n",
            "processed 800000 lines\n",
            "processed 810000 lines\n",
            "processed 820000 lines\n",
            "processed 830000 lines\n",
            "processed 840000 lines\n",
            "processed 850000 lines\n",
            "processed 860000 lines\n",
            "processed 870000 lines\n",
            "processed 880000 lines\n",
            "processed 890000 lines\n",
            "processed 900000 lines\n",
            "processed 910000 lines\n",
            "processed 920000 lines\n",
            "processed 930000 lines\n",
            "processed 940000 lines\n",
            "processed 950000 lines\n",
            "processed 960000 lines\n",
            "processed 970000 lines\n",
            "processed 980000 lines\n",
            "processed 990000 lines\n",
            "processed 1000000 lines\n",
            "processed 1010000 lines\n",
            "processed 1020000 lines\n",
            "processed 1030000 lines\n",
            "processed 1040000 lines\n",
            "processed 1050000 lines\n",
            "processed 1060000 lines\n",
            "processed 1070000 lines\n",
            "processed 1080000 lines\n",
            "processed 1090000 lines\n",
            "processed 1100000 lines\n",
            "processed 1110000 lines\n",
            "processed 1120000 lines\n",
            "processed 1130000 lines\n",
            "processed 1140000 lines\n",
            "processed 1150000 lines\n",
            "processed 1160000 lines\n",
            "processed 1170000 lines\n",
            "processed 1180000 lines\n",
            "processed 1190000 lines\n",
            "processed 1200000 lines\n",
            "processed 1210000 lines\n",
            "processed 1220000 lines\n",
            "processed 1230000 lines\n",
            "processed 1240000 lines\n",
            "processed 1250000 lines\n",
            "processed 1260000 lines\n",
            "processed 1270000 lines\n",
            "processed 1280000 lines\n",
            "processed 1290000 lines\n",
            "processed 1300000 lines\n",
            "processed 1310000 lines\n",
            "processed 1320000 lines\n",
            "processed 1330000 lines\n",
            "processed 1340000 lines\n",
            "processed 1350000 lines\n",
            "processed 1360000 lines\n",
            "processed 1370000 lines\n",
            "processed 1380000 lines\n",
            "processed 1390000 lines\n",
            "processed 1400000 lines\n",
            "processed 1410000 lines\n",
            "processed 1420000 lines\n",
            "processed 1430000 lines\n",
            "processed 1440000 lines\n",
            "processed 1450000 lines\n",
            "processed 1460000 lines\n",
            "processed 1470000 lines\n",
            "processed 1480000 lines\n",
            "processed 1490000 lines\n",
            "processed 1500000 lines\n",
            "processed 1510000 lines\n",
            "processed 1520000 lines\n",
            "processed 1530000 lines\n",
            "processed 1540000 lines\n",
            "processed 1550000 lines\n",
            "processed 1560000 lines\n",
            "processed 1570000 lines\n",
            "processed 1580000 lines\n",
            "processed 1590000 lines\n",
            "processed 1600000 lines\n",
            "processed 1610000 lines\n",
            "processed 1620000 lines\n",
            "processed 1630000 lines\n",
            "processed 1640000 lines\n",
            "processed 1650000 lines\n",
            "processed 1660000 lines\n",
            "processed 1670000 lines\n",
            "processed 1680000 lines\n",
            "processed 1690000 lines\n",
            "processed 1700000 lines\n",
            "processed 1710000 lines\n",
            "processed 1720000 lines\n",
            "processed 1730000 lines\n",
            "processed 1740000 lines\n",
            "processed 1750000 lines\n",
            "processed 1760000 lines\n",
            "processed 1770000 lines\n",
            "processed 1780000 lines\n",
            "processed 1790000 lines\n",
            "processed 1800000 lines\n",
            "processed 1810000 lines\n",
            "processed 1820000 lines\n",
            "processed 1830000 lines\n",
            "processed 1840000 lines\n",
            "processed 1850000 lines\n",
            "processed 1860000 lines\n",
            "processed 1870000 lines\n",
            "processed 1880000 lines\n",
            "processed 1890000 lines\n",
            "processed 1900000 lines\n",
            "processed 1910000 lines\n",
            "processed 1920000 lines\n",
            "processed 1930000 lines\n",
            "processed 1940000 lines\n",
            "processed 1950000 lines\n",
            "processed 1960000 lines\n",
            "processed 1970000 lines\n",
            "processed 1980000 lines\n",
            "processed 1990000 lines\n",
            "processed 2000000 lines\n",
            "processed 2010000 lines\n",
            "processed 2020000 lines\n",
            "processed 2030000 lines\n",
            "processed 2040000 lines\n",
            "processed 2050000 lines\n",
            "processed 2060000 lines\n",
            "processed 2070000 lines\n",
            "processed 2080000 lines\n",
            "processed 2090000 lines\n",
            "processed 2100000 lines\n",
            "processed 2110000 lines\n",
            "processed 2120000 lines\n",
            "processed 2130000 lines\n",
            "processed 2140000 lines\n",
            "processed 2150000 lines\n",
            "processed 2160000 lines\n",
            "processed 2170000 lines\n",
            "processed 2180000 lines\n",
            "processed 2190000 lines\n",
            "processed 2200000 lines\n",
            "processed 2210000 lines\n",
            "processed 2220000 lines\n",
            "processed 2230000 lines\n",
            "processed 2240000 lines\n",
            "processed 2250000 lines\n",
            "processed 2260000 lines\n",
            "processed 2270000 lines\n",
            "processed 2280000 lines\n",
            "processed 2290000 lines\n",
            "processed 2300000 lines\n",
            "processed 2310000 lines\n",
            "processed 2320000 lines\n",
            "processed 2330000 lines\n",
            "processed 2340000 lines\n",
            "processed 2350000 lines\n",
            "processed 2360000 lines\n",
            "processed 2370000 lines\n",
            "processed 2380000 lines\n",
            "processed 2390000 lines\n",
            "processed 2400000 lines\n",
            "processed 2410000 lines\n",
            "processed 2420000 lines\n",
            "processed 2430000 lines\n",
            "processed 2440000 lines\n",
            "processed 2450000 lines\n",
            "processed 2460000 lines\n",
            "processed 2470000 lines\n",
            "processed 2480000 lines\n",
            "processed 2490000 lines\n",
            "processed 2500000 lines\n",
            "processed 2510000 lines\n",
            "processed 2520000 lines\n",
            "processed 2530000 lines\n",
            "processed 2540000 lines\n",
            "processed 2550000 lines\n",
            "processed 2560000 lines\n",
            "processed 2570000 lines\n",
            "processed 2580000 lines\n",
            "processed 2590000 lines\n",
            "processed 2600000 lines\n",
            "processed 2610000 lines\n",
            "processed 2620000 lines\n",
            "processed 2630000 lines\n",
            "processed 2640000 lines\n",
            "processed 2650000 lines\n",
            "processed 2660000 lines\n",
            "processed 2670000 lines\n",
            "processed 2680000 lines\n",
            "processed 2690000 lines\n",
            "processed 2700000 lines\n",
            "processed 2710000 lines\n",
            "processed 2720000 lines\n",
            "processed 2730000 lines\n",
            "processed 2740000 lines\n",
            "processed 2750000 lines\n",
            "processed 2760000 lines\n",
            "processed 2770000 lines\n",
            "processed 2780000 lines\n",
            "processed 2790000 lines\n",
            "processed 2800000 lines\n",
            "processed 2810000 lines\n",
            "processed 2820000 lines\n",
            "processed 2830000 lines\n",
            "processed 2840000 lines\n",
            "processed 2850000 lines\n",
            "processed 2860000 lines\n",
            "processed 2870000 lines\n",
            "processed 2880000 lines\n",
            "processed 2890000 lines\n",
            "processed 2900000 lines\n",
            "processed 2910000 lines\n",
            "processed 2920000 lines\n",
            "processed 2930000 lines\n",
            "processed 2940000 lines\n",
            "processed 2950000 lines\n",
            "processed 2960000 lines\n",
            "processed 2970000 lines\n",
            "processed 2980000 lines\n",
            "processed 2990000 lines\n",
            "processed 3000000 lines\n",
            "processed 3010000 lines\n",
            "processed 3020000 lines\n",
            "processed 3030000 lines\n",
            "processed 3040000 lines\n",
            "processed 3050000 lines\n",
            "processed 3060000 lines\n",
            "processed 3070000 lines\n",
            "processed 3080000 lines\n",
            "processed 3090000 lines\n",
            "processed 3100000 lines\n",
            "processed 3110000 lines\n",
            "processed 3120000 lines\n",
            "processed 3130000 lines\n",
            "processed 3140000 lines\n",
            "processed 3150000 lines\n",
            "processed 3160000 lines\n",
            "processed 3170000 lines\n",
            "processed 3180000 lines\n",
            "processed 3190000 lines\n",
            "processed 3200000 lines\n",
            "processed 3210000 lines\n",
            "processed 3220000 lines\n",
            "processed 3230000 lines\n",
            "processed 3240000 lines\n",
            "processed 3250000 lines\n",
            "processed 3260000 lines\n",
            "processed 3270000 lines\n",
            "processed 3280000 lines\n",
            "skipped 0 empty lines\n",
            "filtered 336 lines\n",
            "processed 10000 lines\n",
            "processed 20000 lines\n",
            "processed 30000 lines\n",
            "processed 40000 lines\n",
            "processed 50000 lines\n",
            "processed 60000 lines\n",
            "processed 70000 lines\n",
            "processed 80000 lines\n",
            "processed 90000 lines\n",
            "processed 100000 lines\n",
            "processed 110000 lines\n",
            "processed 120000 lines\n",
            "processed 130000 lines\n",
            "processed 140000 lines\n",
            "processed 150000 lines\n",
            "processed 160000 lines\n",
            "processed 170000 lines\n",
            "processed 180000 lines\n",
            "processed 190000 lines\n",
            "processed 200000 lines\n",
            "processed 210000 lines\n",
            "processed 220000 lines\n",
            "processed 230000 lines\n",
            "processed 240000 lines\n",
            "processed 250000 lines\n",
            "processed 260000 lines\n",
            "processed 270000 lines\n",
            "processed 280000 lines\n",
            "processed 290000 lines\n",
            "processed 300000 lines\n",
            "processed 310000 lines\n",
            "processed 320000 lines\n",
            "processed 330000 lines\n",
            "processed 340000 lines\n",
            "processed 350000 lines\n",
            "processed 360000 lines\n",
            "processed 370000 lines\n",
            "processed 380000 lines\n",
            "processed 390000 lines\n",
            "processed 400000 lines\n",
            "processed 410000 lines\n",
            "processed 420000 lines\n",
            "processed 430000 lines\n",
            "processed 440000 lines\n",
            "processed 450000 lines\n",
            "processed 460000 lines\n",
            "processed 470000 lines\n",
            "processed 480000 lines\n",
            "processed 490000 lines\n",
            "processed 500000 lines\n",
            "processed 510000 lines\n",
            "processed 520000 lines\n",
            "processed 530000 lines\n",
            "processed 540000 lines\n",
            "processed 550000 lines\n",
            "processed 560000 lines\n",
            "processed 570000 lines\n",
            "processed 580000 lines\n",
            "processed 590000 lines\n",
            "processed 600000 lines\n",
            "processed 610000 lines\n",
            "processed 620000 lines\n",
            "processed 630000 lines\n",
            "processed 640000 lines\n",
            "processed 650000 lines\n",
            "processed 660000 lines\n",
            "processed 670000 lines\n",
            "processed 680000 lines\n",
            "processed 690000 lines\n",
            "processed 700000 lines\n",
            "processed 710000 lines\n",
            "processed 720000 lines\n",
            "processed 730000 lines\n",
            "processed 740000 lines\n",
            "processed 750000 lines\n",
            "processed 760000 lines\n",
            "processed 770000 lines\n",
            "processed 780000 lines\n",
            "processed 790000 lines\n",
            "processed 800000 lines\n",
            "processed 810000 lines\n",
            "processed 820000 lines\n",
            "processed 830000 lines\n",
            "processed 840000 lines\n",
            "processed 850000 lines\n",
            "processed 860000 lines\n",
            "processed 870000 lines\n",
            "processed 880000 lines\n",
            "processed 890000 lines\n",
            "processed 900000 lines\n",
            "processed 910000 lines\n",
            "processed 920000 lines\n",
            "processed 930000 lines\n",
            "processed 940000 lines\n",
            "processed 950000 lines\n",
            "processed 960000 lines\n",
            "processed 970000 lines\n",
            "processed 980000 lines\n",
            "processed 990000 lines\n",
            "processed 1000000 lines\n",
            "processed 1010000 lines\n",
            "processed 1020000 lines\n",
            "processed 1030000 lines\n",
            "processed 1040000 lines\n",
            "processed 1050000 lines\n",
            "processed 1060000 lines\n",
            "processed 1070000 lines\n",
            "processed 1080000 lines\n",
            "processed 1090000 lines\n",
            "processed 1100000 lines\n",
            "processed 1110000 lines\n",
            "processed 1120000 lines\n",
            "processed 1130000 lines\n",
            "processed 1140000 lines\n",
            "processed 1150000 lines\n",
            "processed 1160000 lines\n",
            "processed 1170000 lines\n",
            "processed 1180000 lines\n",
            "processed 1190000 lines\n",
            "processed 1200000 lines\n",
            "processed 1210000 lines\n",
            "processed 1220000 lines\n",
            "processed 1230000 lines\n",
            "processed 1240000 lines\n",
            "processed 1250000 lines\n",
            "processed 1260000 lines\n",
            "processed 1270000 lines\n",
            "processed 1280000 lines\n",
            "processed 1290000 lines\n",
            "processed 1300000 lines\n",
            "processed 1310000 lines\n",
            "processed 1320000 lines\n",
            "processed 1330000 lines\n",
            "processed 1340000 lines\n",
            "processed 1350000 lines\n",
            "processed 1360000 lines\n",
            "processed 1370000 lines\n",
            "processed 1380000 lines\n",
            "processed 1390000 lines\n",
            "processed 1400000 lines\n",
            "processed 1410000 lines\n",
            "processed 1420000 lines\n",
            "processed 1430000 lines\n",
            "processed 1440000 lines\n",
            "processed 1450000 lines\n",
            "processed 1460000 lines\n",
            "processed 1470000 lines\n",
            "processed 1480000 lines\n",
            "processed 1490000 lines\n",
            "processed 1500000 lines\n",
            "processed 1510000 lines\n",
            "processed 1520000 lines\n",
            "processed 1530000 lines\n",
            "processed 1540000 lines\n",
            "processed 1550000 lines\n",
            "processed 1560000 lines\n",
            "processed 1570000 lines\n",
            "processed 1580000 lines\n",
            "processed 1590000 lines\n",
            "processed 1600000 lines\n",
            "processed 1610000 lines\n",
            "processed 1620000 lines\n",
            "processed 1630000 lines\n",
            "processed 1640000 lines\n",
            "processed 1650000 lines\n",
            "processed 1660000 lines\n",
            "processed 1670000 lines\n",
            "processed 1680000 lines\n",
            "processed 1690000 lines\n",
            "processed 1700000 lines\n",
            "processed 1710000 lines\n",
            "processed 1720000 lines\n",
            "processed 1730000 lines\n",
            "processed 1740000 lines\n",
            "processed 1750000 lines\n",
            "processed 1760000 lines\n",
            "processed 1770000 lines\n",
            "processed 1780000 lines\n",
            "processed 1790000 lines\n",
            "processed 1800000 lines\n",
            "processed 1810000 lines\n",
            "processed 1820000 lines\n",
            "processed 1830000 lines\n",
            "processed 1840000 lines\n",
            "processed 1850000 lines\n",
            "processed 1860000 lines\n",
            "processed 1870000 lines\n",
            "processed 1880000 lines\n",
            "processed 1890000 lines\n",
            "processed 1900000 lines\n",
            "processed 1910000 lines\n",
            "processed 1920000 lines\n",
            "processed 1930000 lines\n",
            "processed 1940000 lines\n",
            "processed 1950000 lines\n",
            "processed 1960000 lines\n",
            "processed 1970000 lines\n",
            "processed 1980000 lines\n",
            "processed 1990000 lines\n",
            "processed 2000000 lines\n",
            "processed 2010000 lines\n",
            "processed 2020000 lines\n",
            "processed 2030000 lines\n",
            "processed 2040000 lines\n",
            "processed 2050000 lines\n",
            "processed 2060000 lines\n",
            "processed 2070000 lines\n",
            "processed 2080000 lines\n",
            "processed 2090000 lines\n",
            "processed 2100000 lines\n",
            "processed 2110000 lines\n",
            "processed 2120000 lines\n",
            "processed 2130000 lines\n",
            "processed 2140000 lines\n",
            "processed 2150000 lines\n",
            "processed 2160000 lines\n",
            "processed 2170000 lines\n",
            "processed 2180000 lines\n",
            "processed 2190000 lines\n",
            "processed 2200000 lines\n",
            "processed 2210000 lines\n",
            "processed 2220000 lines\n",
            "processed 2230000 lines\n",
            "processed 2240000 lines\n",
            "processed 2250000 lines\n",
            "processed 2260000 lines\n",
            "processed 2270000 lines\n",
            "processed 2280000 lines\n",
            "processed 2290000 lines\n",
            "processed 2300000 lines\n",
            "processed 2310000 lines\n",
            "processed 2320000 lines\n",
            "processed 2330000 lines\n",
            "processed 2340000 lines\n",
            "processed 2350000 lines\n",
            "processed 2360000 lines\n",
            "processed 2370000 lines\n",
            "processed 2380000 lines\n",
            "processed 2390000 lines\n",
            "processed 2400000 lines\n",
            "processed 2410000 lines\n",
            "processed 2420000 lines\n",
            "processed 2430000 lines\n",
            "processed 2440000 lines\n",
            "processed 2450000 lines\n",
            "processed 2460000 lines\n",
            "processed 2470000 lines\n",
            "processed 2480000 lines\n",
            "processed 2490000 lines\n",
            "processed 2500000 lines\n",
            "processed 2510000 lines\n",
            "processed 2520000 lines\n",
            "processed 2530000 lines\n",
            "processed 2540000 lines\n",
            "processed 2550000 lines\n",
            "processed 2560000 lines\n",
            "processed 2570000 lines\n",
            "processed 2580000 lines\n",
            "processed 2590000 lines\n",
            "processed 2600000 lines\n",
            "processed 2610000 lines\n",
            "processed 2620000 lines\n",
            "processed 2630000 lines\n",
            "processed 2640000 lines\n",
            "processed 2650000 lines\n",
            "processed 2660000 lines\n",
            "processed 2670000 lines\n",
            "processed 2680000 lines\n",
            "processed 2690000 lines\n",
            "processed 2700000 lines\n",
            "processed 2710000 lines\n",
            "processed 2720000 lines\n",
            "processed 2730000 lines\n",
            "processed 2740000 lines\n",
            "processed 2750000 lines\n",
            "processed 2760000 lines\n",
            "processed 2770000 lines\n",
            "processed 2780000 lines\n",
            "processed 2790000 lines\n",
            "processed 2800000 lines\n",
            "processed 2810000 lines\n",
            "processed 2820000 lines\n",
            "processed 2830000 lines\n",
            "processed 2840000 lines\n",
            "processed 2850000 lines\n",
            "processed 2860000 lines\n",
            "processed 2870000 lines\n",
            "processed 2880000 lines\n",
            "processed 2890000 lines\n",
            "processed 2900000 lines\n",
            "processed 2910000 lines\n",
            "processed 2920000 lines\n",
            "processed 2930000 lines\n",
            "processed 2940000 lines\n",
            "processed 2950000 lines\n",
            "processed 2960000 lines\n",
            "processed 2970000 lines\n",
            "processed 2980000 lines\n",
            "processed 2990000 lines\n",
            "processed 3000000 lines\n",
            "processed 3010000 lines\n",
            "processed 3020000 lines\n",
            "processed 3030000 lines\n",
            "processed 3040000 lines\n",
            "processed 3050000 lines\n",
            "processed 3060000 lines\n",
            "processed 3070000 lines\n",
            "processed 3080000 lines\n",
            "processed 3090000 lines\n",
            "processed 3100000 lines\n",
            "processed 3110000 lines\n",
            "processed 3120000 lines\n",
            "processed 3130000 lines\n",
            "processed 3140000 lines\n",
            "processed 3150000 lines\n",
            "processed 3160000 lines\n",
            "processed 3170000 lines\n",
            "processed 3180000 lines\n",
            "processed 3190000 lines\n",
            "processed 3200000 lines\n",
            "processed 3210000 lines\n",
            "processed 3220000 lines\n",
            "processed 3230000 lines\n",
            "processed 3240000 lines\n",
            "processed 3250000 lines\n",
            "processed 3260000 lines\n",
            "processed 3270000 lines\n",
            "processed 3280000 lines\n",
            "processed 3290000 lines\n",
            "processed 3300000 lines\n",
            "processed 3310000 lines\n",
            "processed 3320000 lines\n",
            "processed 3330000 lines\n",
            "processed 3340000 lines\n",
            "processed 3350000 lines\n",
            "processed 3360000 lines\n",
            "processed 3370000 lines\n",
            "processed 3380000 lines\n",
            "processed 3390000 lines\n",
            "processed 3400000 lines\n",
            "processed 3410000 lines\n",
            "processed 3420000 lines\n",
            "processed 3430000 lines\n",
            "processed 3440000 lines\n",
            "processed 3450000 lines\n",
            "processed 3460000 lines\n",
            "processed 3470000 lines\n",
            "processed 3480000 lines\n",
            "processed 3490000 lines\n",
            "processed 3500000 lines\n",
            "processed 3510000 lines\n",
            "processed 3520000 lines\n",
            "processed 3530000 lines\n",
            "processed 3540000 lines\n",
            "processed 3550000 lines\n",
            "processed 3560000 lines\n",
            "processed 3570000 lines\n",
            "processed 3580000 lines\n",
            "processed 3590000 lines\n",
            "processed 3600000 lines\n",
            "processed 3610000 lines\n",
            "processed 3620000 lines\n",
            "processed 3630000 lines\n",
            "processed 3640000 lines\n",
            "processed 3650000 lines\n",
            "processed 3660000 lines\n",
            "processed 3670000 lines\n",
            "processed 3680000 lines\n",
            "processed 3690000 lines\n",
            "processed 3700000 lines\n",
            "processed 3710000 lines\n",
            "processed 3720000 lines\n",
            "processed 3730000 lines\n",
            "processed 3740000 lines\n",
            "processed 3750000 lines\n",
            "processed 3760000 lines\n",
            "processed 3770000 lines\n",
            "processed 3780000 lines\n",
            "processed 3790000 lines\n",
            "processed 3800000 lines\n",
            "processed 3810000 lines\n",
            "processed 3820000 lines\n",
            "processed 3830000 lines\n",
            "processed 3840000 lines\n",
            "processed 3850000 lines\n",
            "processed 3860000 lines\n",
            "processed 3870000 lines\n",
            "processed 3880000 lines\n",
            "processed 3890000 lines\n",
            "processed 3900000 lines\n",
            "processed 3910000 lines\n",
            "processed 3920000 lines\n",
            "processed 3930000 lines\n",
            "processed 3940000 lines\n",
            "processed 3950000 lines\n",
            "processed 3960000 lines\n",
            "processed 3970000 lines\n",
            "processed 3980000 lines\n",
            "processed 3990000 lines\n",
            "processed 4000000 lines\n",
            "processed 4010000 lines\n",
            "processed 4020000 lines\n",
            "processed 4030000 lines\n",
            "processed 4040000 lines\n",
            "processed 4050000 lines\n",
            "processed 4060000 lines\n",
            "processed 4070000 lines\n",
            "processed 4080000 lines\n",
            "processed 4090000 lines\n",
            "processed 4100000 lines\n",
            "processed 4110000 lines\n",
            "processed 4120000 lines\n",
            "processed 4130000 lines\n",
            "processed 4140000 lines\n",
            "processed 4150000 lines\n",
            "processed 4160000 lines\n",
            "processed 4170000 lines\n",
            "processed 4180000 lines\n",
            "processed 4190000 lines\n",
            "processed 4200000 lines\n",
            "processed 4210000 lines\n",
            "processed 4220000 lines\n",
            "processed 4230000 lines\n",
            "processed 4240000 lines\n",
            "processed 4250000 lines\n",
            "processed 4260000 lines\n",
            "processed 4270000 lines\n",
            "processed 4280000 lines\n",
            "processed 4290000 lines\n",
            "processed 4300000 lines\n",
            "processed 4310000 lines\n",
            "processed 4320000 lines\n",
            "processed 4330000 lines\n",
            "processed 4340000 lines\n",
            "processed 4350000 lines\n",
            "processed 4360000 lines\n",
            "processed 4370000 lines\n",
            "processed 4380000 lines\n",
            "processed 4390000 lines\n",
            "processed 4400000 lines\n",
            "processed 4410000 lines\n",
            "processed 4420000 lines\n",
            "processed 4430000 lines\n",
            "processed 4440000 lines\n",
            "processed 4450000 lines\n",
            "processed 4460000 lines\n",
            "processed 4470000 lines\n",
            "processed 4480000 lines\n",
            "processed 4490000 lines\n",
            "processed 4500000 lines\n",
            "processed 4510000 lines\n",
            "processed 4520000 lines\n",
            "processed 4530000 lines\n",
            "processed 4540000 lines\n",
            "processed 4550000 lines\n",
            "processed 4560000 lines\n",
            "processed 4570000 lines\n",
            "processed 4580000 lines\n",
            "processed 4590000 lines\n",
            "processed 4600000 lines\n",
            "processed 4610000 lines\n",
            "processed 4620000 lines\n",
            "processed 4630000 lines\n",
            "processed 4640000 lines\n",
            "processed 4650000 lines\n",
            "processed 4660000 lines\n",
            "processed 4670000 lines\n",
            "processed 4680000 lines\n",
            "processed 4690000 lines\n",
            "processed 4700000 lines\n",
            "processed 4710000 lines\n",
            "processed 4720000 lines\n",
            "processed 4730000 lines\n",
            "processed 4740000 lines\n",
            "processed 4750000 lines\n",
            "processed 4760000 lines\n",
            "processed 4770000 lines\n",
            "processed 4780000 lines\n",
            "processed 4790000 lines\n",
            "processed 4800000 lines\n",
            "processed 4810000 lines\n",
            "processed 4820000 lines\n",
            "processed 4830000 lines\n",
            "processed 4840000 lines\n",
            "processed 4850000 lines\n",
            "processed 4860000 lines\n",
            "processed 4870000 lines\n",
            "processed 4880000 lines\n",
            "processed 4890000 lines\n",
            "processed 4900000 lines\n",
            "processed 4910000 lines\n",
            "processed 4920000 lines\n",
            "processed 4930000 lines\n",
            "processed 4940000 lines\n",
            "processed 4950000 lines\n",
            "processed 4960000 lines\n",
            "processed 4970000 lines\n",
            "processed 4980000 lines\n",
            "processed 4990000 lines\n",
            "processed 5000000 lines\n",
            "processed 5010000 lines\n",
            "processed 5020000 lines\n",
            "processed 5030000 lines\n",
            "processed 5040000 lines\n",
            "processed 5050000 lines\n",
            "processed 5060000 lines\n",
            "processed 5070000 lines\n",
            "processed 5080000 lines\n",
            "processed 5090000 lines\n",
            "processed 5100000 lines\n",
            "processed 5110000 lines\n",
            "processed 5120000 lines\n",
            "processed 5130000 lines\n",
            "processed 5140000 lines\n",
            "processed 5150000 lines\n",
            "processed 5160000 lines\n",
            "processed 5170000 lines\n",
            "processed 5180000 lines\n",
            "processed 5190000 lines\n",
            "processed 5200000 lines\n",
            "processed 5210000 lines\n",
            "processed 5220000 lines\n",
            "processed 5230000 lines\n",
            "processed 5240000 lines\n",
            "processed 5250000 lines\n",
            "processed 5260000 lines\n",
            "processed 5270000 lines\n",
            "processed 5280000 lines\n",
            "processed 5290000 lines\n",
            "processed 5300000 lines\n",
            "processed 5310000 lines\n",
            "processed 5320000 lines\n",
            "processed 5330000 lines\n",
            "processed 5340000 lines\n",
            "processed 5350000 lines\n",
            "processed 5360000 lines\n",
            "processed 5370000 lines\n",
            "processed 5380000 lines\n",
            "processed 5390000 lines\n",
            "processed 5400000 lines\n",
            "processed 5410000 lines\n",
            "processed 5420000 lines\n",
            "processed 5430000 lines\n",
            "processed 5440000 lines\n",
            "processed 5450000 lines\n",
            "processed 5460000 lines\n",
            "processed 5470000 lines\n",
            "processed 5480000 lines\n",
            "processed 5490000 lines\n",
            "processed 5500000 lines\n",
            "processed 5510000 lines\n",
            "processed 5520000 lines\n",
            "processed 5530000 lines\n",
            "processed 5540000 lines\n",
            "processed 5550000 lines\n",
            "processed 5560000 lines\n",
            "processed 5570000 lines\n",
            "processed 5580000 lines\n",
            "processed 5590000 lines\n",
            "processed 5600000 lines\n",
            "processed 5610000 lines\n",
            "processed 5620000 lines\n",
            "processed 5630000 lines\n",
            "processed 5640000 lines\n",
            "processed 5650000 lines\n",
            "processed 5660000 lines\n",
            "processed 5670000 lines\n",
            "processed 5680000 lines\n",
            "processed 5690000 lines\n",
            "processed 5700000 lines\n",
            "processed 5710000 lines\n",
            "processed 5720000 lines\n",
            "processed 5730000 lines\n",
            "processed 5740000 lines\n",
            "processed 5750000 lines\n",
            "processed 5760000 lines\n",
            "processed 5770000 lines\n",
            "processed 5780000 lines\n",
            "processed 5790000 lines\n",
            "processed 5800000 lines\n",
            "processed 5810000 lines\n",
            "processed 5820000 lines\n",
            "processed 5830000 lines\n",
            "processed 5840000 lines\n",
            "processed 5850000 lines\n",
            "processed 5860000 lines\n",
            "processed 5870000 lines\n",
            "processed 5880000 lines\n",
            "processed 5890000 lines\n",
            "processed 5900000 lines\n",
            "processed 5910000 lines\n",
            "processed 5920000 lines\n",
            "processed 5930000 lines\n",
            "processed 5940000 lines\n",
            "processed 5950000 lines\n",
            "processed 5960000 lines\n",
            "processed 5970000 lines\n",
            "processed 5980000 lines\n",
            "processed 5990000 lines\n",
            "processed 6000000 lines\n",
            "processed 6010000 lines\n",
            "processed 6020000 lines\n",
            "processed 6030000 lines\n",
            "processed 6040000 lines\n",
            "processed 6050000 lines\n",
            "processed 6060000 lines\n",
            "processed 6070000 lines\n",
            "processed 6080000 lines\n",
            "processed 6090000 lines\n",
            "processed 6100000 lines\n",
            "processed 6110000 lines\n",
            "processed 6120000 lines\n",
            "processed 6130000 lines\n",
            "processed 6140000 lines\n",
            "processed 6150000 lines\n",
            "processed 6160000 lines\n",
            "processed 6170000 lines\n",
            "processed 6180000 lines\n",
            "processed 6190000 lines\n",
            "processed 6200000 lines\n",
            "processed 6210000 lines\n",
            "processed 6220000 lines\n",
            "processed 6230000 lines\n",
            "processed 6240000 lines\n",
            "processed 6250000 lines\n",
            "processed 6260000 lines\n",
            "processed 6270000 lines\n",
            "processed 6280000 lines\n",
            "processed 6290000 lines\n",
            "processed 6300000 lines\n",
            "processed 6310000 lines\n",
            "processed 6320000 lines\n",
            "processed 6330000 lines\n",
            "processed 6340000 lines\n",
            "processed 6350000 lines\n",
            "processed 6360000 lines\n",
            "processed 6370000 lines\n",
            "processed 6380000 lines\n",
            "processed 6390000 lines\n",
            "processed 6400000 lines\n",
            "processed 6410000 lines\n",
            "processed 6420000 lines\n",
            "processed 6430000 lines\n",
            "processed 6440000 lines\n",
            "processed 6450000 lines\n",
            "processed 6460000 lines\n",
            "processed 6470000 lines\n",
            "processed 6480000 lines\n",
            "processed 6490000 lines\n",
            "processed 6500000 lines\n",
            "processed 6510000 lines\n",
            "processed 6520000 lines\n",
            "processed 6530000 lines\n",
            "processed 6540000 lines\n",
            "processed 6550000 lines\n",
            "processed 6560000 lines\n",
            "processed 6570000 lines\n",
            "processed 6580000 lines\n",
            "processed 6590000 lines\n",
            "processed 6600000 lines\n",
            "processed 6610000 lines\n",
            "processed 6620000 lines\n",
            "processed 6630000 lines\n",
            "processed 6640000 lines\n",
            "processed 6650000 lines\n",
            "processed 6660000 lines\n",
            "processed 6670000 lines\n",
            "processed 6680000 lines\n",
            "processed 6690000 lines\n",
            "processed 6700000 lines\n",
            "processed 6710000 lines\n",
            "processed 6720000 lines\n",
            "processed 6730000 lines\n",
            "processed 6740000 lines\n",
            "processed 6750000 lines\n",
            "processed 6760000 lines\n",
            "processed 6770000 lines\n",
            "processed 6780000 lines\n",
            "processed 6790000 lines\n",
            "processed 6800000 lines\n",
            "processed 6810000 lines\n",
            "processed 6820000 lines\n",
            "processed 6830000 lines\n",
            "processed 6840000 lines\n",
            "processed 6850000 lines\n",
            "processed 6860000 lines\n",
            "processed 6870000 lines\n",
            "processed 6880000 lines\n",
            "processed 6890000 lines\n",
            "processed 6900000 lines\n",
            "processed 6910000 lines\n",
            "processed 6920000 lines\n",
            "processed 6930000 lines\n",
            "processed 6940000 lines\n",
            "processed 6950000 lines\n",
            "processed 6960000 lines\n",
            "processed 6970000 lines\n",
            "processed 6980000 lines\n",
            "processed 6990000 lines\n",
            "processed 7000000 lines\n",
            "processed 7010000 lines\n",
            "processed 7020000 lines\n",
            "processed 7030000 lines\n",
            "processed 7040000 lines\n",
            "processed 7050000 lines\n",
            "processed 7060000 lines\n",
            "processed 7070000 lines\n",
            "processed 7080000 lines\n",
            "processed 7090000 lines\n",
            "processed 7100000 lines\n",
            "processed 7110000 lines\n",
            "processed 7120000 lines\n",
            "processed 7130000 lines\n",
            "processed 7140000 lines\n",
            "processed 7150000 lines\n",
            "processed 7160000 lines\n",
            "processed 7170000 lines\n",
            "processed 7180000 lines\n",
            "processed 7190000 lines\n",
            "processed 7200000 lines\n",
            "processed 7210000 lines\n",
            "processed 7220000 lines\n",
            "processed 7230000 lines\n",
            "processed 7240000 lines\n",
            "processed 7250000 lines\n",
            "processed 7260000 lines\n",
            "processed 7270000 lines\n",
            "processed 7280000 lines\n",
            "processed 7290000 lines\n",
            "processed 7300000 lines\n",
            "processed 7310000 lines\n",
            "processed 7320000 lines\n",
            "processed 7330000 lines\n",
            "processed 7340000 lines\n",
            "processed 7350000 lines\n",
            "processed 7360000 lines\n",
            "processed 7370000 lines\n",
            "processed 7380000 lines\n",
            "processed 7390000 lines\n",
            "processed 7400000 lines\n",
            "processed 7410000 lines\n",
            "processed 7420000 lines\n",
            "processed 7430000 lines\n",
            "processed 7440000 lines\n",
            "processed 7450000 lines\n",
            "processed 7460000 lines\n",
            "processed 7470000 lines\n",
            "processed 7480000 lines\n",
            "processed 7490000 lines\n",
            "processed 7500000 lines\n",
            "processed 7510000 lines\n",
            "processed 7520000 lines\n",
            "processed 7530000 lines\n",
            "processed 7540000 lines\n",
            "processed 7550000 lines\n",
            "processed 7560000 lines\n",
            "processed 7570000 lines\n",
            "processed 7580000 lines\n",
            "processed 7590000 lines\n",
            "processed 7600000 lines\n",
            "processed 7610000 lines\n",
            "processed 7620000 lines\n",
            "processed 7630000 lines\n",
            "processed 7640000 lines\n",
            "processed 7650000 lines\n",
            "processed 7660000 lines\n",
            "processed 7670000 lines\n",
            "processed 7680000 lines\n",
            "processed 7690000 lines\n",
            "processed 7700000 lines\n",
            "processed 7710000 lines\n",
            "processed 7720000 lines\n",
            "processed 7730000 lines\n",
            "processed 7740000 lines\n",
            "processed 7750000 lines\n",
            "processed 7760000 lines\n",
            "processed 7770000 lines\n",
            "processed 7780000 lines\n",
            "processed 7790000 lines\n",
            "processed 7800000 lines\n",
            "processed 7810000 lines\n",
            "processed 7820000 lines\n",
            "processed 7830000 lines\n",
            "processed 7840000 lines\n",
            "processed 7850000 lines\n",
            "processed 7860000 lines\n",
            "processed 7870000 lines\n",
            "processed 7880000 lines\n",
            "processed 7890000 lines\n",
            "processed 7900000 lines\n",
            "processed 7910000 lines\n",
            "processed 7920000 lines\n",
            "processed 7930000 lines\n",
            "processed 7940000 lines\n",
            "processed 7950000 lines\n",
            "processed 7960000 lines\n",
            "processed 7970000 lines\n",
            "processed 7980000 lines\n",
            "processed 7990000 lines\n",
            "processed 8000000 lines\n",
            "processed 8010000 lines\n",
            "processed 8020000 lines\n",
            "processed 8030000 lines\n",
            "processed 8040000 lines\n",
            "processed 8050000 lines\n",
            "processed 8060000 lines\n",
            "processed 8070000 lines\n",
            "processed 8080000 lines\n",
            "processed 8090000 lines\n",
            "processed 8100000 lines\n",
            "processed 8110000 lines\n",
            "processed 8120000 lines\n",
            "processed 8130000 lines\n",
            "processed 8140000 lines\n",
            "processed 8150000 lines\n",
            "processed 8160000 lines\n",
            "processed 8170000 lines\n",
            "processed 8180000 lines\n",
            "processed 8190000 lines\n",
            "processed 8200000 lines\n",
            "processed 8210000 lines\n",
            "processed 8220000 lines\n",
            "processed 8230000 lines\n",
            "processed 8240000 lines\n",
            "processed 8250000 lines\n",
            "processed 8260000 lines\n",
            "processed 8270000 lines\n",
            "processed 8280000 lines\n",
            "processed 8290000 lines\n",
            "processed 8300000 lines\n",
            "processed 8310000 lines\n",
            "processed 8320000 lines\n",
            "processed 8330000 lines\n",
            "processed 8340000 lines\n",
            "processed 8350000 lines\n",
            "processed 8360000 lines\n",
            "processed 8370000 lines\n",
            "processed 8380000 lines\n",
            "processed 8390000 lines\n",
            "processed 8400000 lines\n",
            "processed 8410000 lines\n",
            "processed 8420000 lines\n",
            "processed 8430000 lines\n",
            "processed 8440000 lines\n",
            "processed 8450000 lines\n",
            "processed 8460000 lines\n",
            "skipped 0 empty lines\n",
            "filtered 4093 lines\n",
            "encoding valid with learned BPE...\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9jPC0qKo-c5",
        "outputId": "33b8a3d3-5de8-417d-f61c-fc37dd3f20a0"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MNMT_mr-hi-en_/fairseq/examples/translation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohgYQwYJpCaQ",
        "outputId": "4bb341a6-ccb1-4d0a-cd28-6bbacc504801"
      },
      "source": [
        "%cd /content/drive/My Drive/MNMT_mr-hi-en_/fairseq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MNMT_mr-hi-en_/fairseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aeuk5xmxpF6W",
        "outputId": "9fc3e607-9a24-49a7-ae72-17c1536c67d8"
      },
      "source": [
        "!pip install --editable ./"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/drive/My%20Drive/MNMT_mr-hi-en_/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+286218a) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+286218a) (1.9.0+cu102)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+286218a) (0.29.23)\n",
            "Requirement already satisfied: numpy; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+286218a) (1.19.5)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+286218a) (1.14.5)\n",
            "Collecting hydra-core<1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e3/fbd70dd0d3ce4d1d75c22d56c0c9f895cfa7ed6587a9ffb821d6812d6a60/hydra_core-1.0.6-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+286218a) (2019.12.20)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+286218a) (1.5.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==1.0.0a0+286218a) (3.7.4.3)\n",
            "Collecting PyYAML>=5.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 29.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+286218a) (2.20)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 32.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+286218a) (5.2.0)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+286218a) (2.0.0)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1->fairseq==1.0.0a0+286218a) (3.4.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=12cb43b4c7832a2ebac79289e3f1732cad04189018f02450b8cb9e5981115b78\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, omegaconf, antlr4-python3-runtime, hydra-core, fairseq\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 fairseq hydra-core-1.0.6 omegaconf-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSp2kN4XpLFl",
        "outputId": "47ca56da-12e7-4ebe-eb79-a9634aa437dc"
      },
      "source": [
        "# Binarize the mr-en dataset\n",
        "\n",
        "!fairseq-preprocess --source-lang mr --target-lang en \\\n",
        "    --trainpref /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/train.bpe.mr-en \\\n",
        "    --validpref /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/valid.bpe.mr-en  \\\n",
        "    --destdir data-bin/mr_hi.en.bpe16k \\\n",
        "    --workers 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-06 07:57:02 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/mr_hi.en.bpe16k', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='mr', srcdict=None, suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/train.bpe.mr-en', use_plasma_view=False, user_dir=None, validpref='/content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/valid.bpe.mr-en', wandb_project=None, workers=10)\n",
            "2021-07-06 08:03:33 | INFO | fairseq_cli.preprocess | [mr] Dictionary: 12336 types\n",
            "2021-07-06 08:09:52 | INFO | fairseq_cli.preprocess | [mr] /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/train.bpe.mr-en.mr: 3279706 sents, 61956407 tokens, 0.0% replaced by <unk>\n",
            "2021-07-06 08:09:53 | INFO | fairseq_cli.preprocess | [mr] Dictionary: 12336 types\n",
            "2021-07-06 08:09:54 | INFO | fairseq_cli.preprocess | [mr] /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/valid.bpe.mr-en.mr: 8874 sents, 166955 tokens, 0.00299% replaced by <unk>\n",
            "2021-07-06 08:09:54 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6760 types\n",
            "2021-07-06 08:15:08 | INFO | fairseq_cli.preprocess | [en] /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/train.bpe.mr-en.en: 3279706 sents, 54365956 tokens, 0.0% replaced by <unk>\n",
            "2021-07-06 08:15:08 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6760 types\n",
            "2021-07-06 08:15:10 | INFO | fairseq_cli.preprocess | [en] /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/valid.bpe.mr-en.en: 8874 sents, 146446 tokens, 0.0% replaced by <unk>\n",
            "2021-07-06 08:15:10 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/mr_hi.en.bpe16k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW_jySR7pOGM",
        "outputId": "677406a9-5764-4aaf-a658-5c8050e6447c"
      },
      "source": [
        "# Binarize the hi-en dataset\n",
        "# NOTE: it's important to reuse the en dictionary from the previous step\n",
        "\n",
        "!fairseq-preprocess --source-lang hi --target-lang en \\\n",
        "    --trainpref /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/train.bpe.hi-en  \\\n",
        "    --validpref /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/valid.bpe.hi-en  \\\n",
        "    --tgtdict data-bin/mr_hi.en.bpe16k/dict.en.txt \\\n",
        "    --destdir data-bin/mr_hi.en.bpe16k \\\n",
        "    --workers 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-06 08:15:12 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/mr_hi.en.bpe16k', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='hi', srcdict=None, suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='data-bin/mr_hi.en.bpe16k/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/train.bpe.hi-en', use_plasma_view=False, user_dir=None, validpref='/content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/valid.bpe.hi-en', wandb_project=None, workers=10)\n",
            "2021-07-06 08:27:28 | INFO | fairseq_cli.preprocess | [hi] Dictionary: 15776 types\n",
            "2021-07-06 08:48:00 | INFO | fairseq_cli.preprocess | [hi] /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/train.bpe.hi-en.hi: 8456698 sents, 225819988 tokens, 0.0% replaced by <unk>\n",
            "2021-07-06 08:48:01 | INFO | fairseq_cli.preprocess | [hi] Dictionary: 15776 types\n",
            "2021-07-06 08:48:02 | INFO | fairseq_cli.preprocess | [hi] /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/valid.bpe.hi-en.hi: 6307 sents, 167383 tokens, 0.000597% replaced by <unk>\n",
            "2021-07-06 08:48:02 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6760 types\n",
            "2021-07-06 09:05:13 | INFO | fairseq_cli.preprocess | [en] /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/train.bpe.hi-en.en: 8456698 sents, 210491408 tokens, 2.85e-06% replaced by <unk>\n",
            "2021-07-06 09:05:13 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6760 types\n",
            "2021-07-06 09:05:15 | INFO | fairseq_cli.preprocess | [en] /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq/examples/translation/mr_hi.en.bpe16k/valid.bpe.hi-en.en: 6307 sents, 154873 tokens, 0.0% replaced by <unk>\n",
            "2021-07-06 09:05:15 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/mr_hi.en.bpe16k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaIdz5vScXPA",
        "outputId": "82dd9dea-db31-4458-c0a3-7246145b5064"
      },
      "source": [
        "%cd /content/drive/MyDrive/MNMT_mr-hi-en_/fairseq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MNMT_mr-hi-en_/fairseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXHg1is2HIZd",
        "outputId": "f52f3f2c-b53a-4989-8a8b-de504f1eecfb"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MNMT_mr-hi-en_/fairseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxpBJjb3HM3T"
      },
      "source": [
        "!mkdir -p checkpoints/multilingual_transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfzKscjGGt_q",
        "outputId": "8da55985-f7a2-474a-e79a-930716223431"
      },
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/mr_hi.en.bpe16k/ \\\n",
        "    --max-epoch 50 \\\n",
        "    --ddp-backend=legacy_ddp \\\n",
        "    --task multilingual_translation --lang-pairs mr-en,hi-en \\\n",
        "    --arch multilingual_transformer_iwslt_de_en \\\n",
        "    --share-decoders --share-decoder-input-output-embed \\\n",
        "    --optimizer adam --adam-betas '(0.9, 0.98)' \\\n",
        "    --lr 0.0005 --lr-scheduler inverse_sqrt \\\n",
        "    --warmup-updates 4000 --warmup-init-lr '1e-07' \\\n",
        "    --label-smoothing 0.1 --criterion label_smoothed_cross_entropy \\\n",
        "    --dropout 0.3 --weight-decay 0.0001 \\\n",
        "    --save-dir checkpoints/multilingual_transformer \\\n",
        "    --max-tokens 4000 \\\n",
        "    --update-freq 8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2021-07-09 14:14:43 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 50, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints/multilingual_transformer', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='multilingual_transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='multilingual_transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/mr_hi.en.bpe16k/', data_buffer_size=10, dataset_impl=None, ddp_backend='legacy_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_langtok=None, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_pairs='mr-en,hi-en', layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=50, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/multilingual_transformer', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_embeddings=False, share_decoder_input_output_embed=True, share_decoders=True, share_encoder_embeddings=False, share_encoders=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang=None, task='multilingual_translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', unk=3, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': Namespace(_name='multilingual_translation', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='multilingual_transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/mr_hi.en.bpe16k/', data_buffer_size=10, dataset_impl=None, ddp_backend='legacy_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_langtok=None, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_pairs='mr-en,hi-en', layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=50, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/multilingual_transformer', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_embeddings=False, share_decoder_input_output_embed=True, share_decoders=True, share_encoder_embeddings=False, share_encoders=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang=None, task='multilingual_translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', unk=3, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}\n",
            "2021-07-09 14:14:44 | INFO | fairseq.tasks.multilingual_translation | [en] dictionary: 6760 types\n",
            "2021-07-09 14:14:45 | INFO | fairseq.tasks.multilingual_translation | [hi] dictionary: 15776 types\n",
            "2021-07-09 14:14:46 | INFO | fairseq.tasks.multilingual_translation | [mr] dictionary: 12336 types\n",
            "2021-07-09 14:14:47 | INFO | fairseq_cli.train | MultilingualTransformerModel(\n",
            "  (models): ModuleDict(\n",
            "    (mr-en): FairseqEncoderDecoderModel(\n",
            "      (encoder): TransformerEncoder(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (embed_tokens): Embedding(12336, 512, padding_idx=1)\n",
            "        (embed_positions): SinusoidalPositionalEmbedding()\n",
            "        (layers): ModuleList(\n",
            "          (0): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (1): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (2): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (3): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (4): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (5): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (decoder): TransformerDecoder(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (embed_tokens): Embedding(6760, 512, padding_idx=1)\n",
            "        (embed_positions): SinusoidalPositionalEmbedding()\n",
            "        (layers): ModuleList(\n",
            "          (0): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (1): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (2): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (3): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (4): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (5): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (output_projection): Linear(in_features=512, out_features=6760, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (hi-en): FairseqEncoderDecoderModel(\n",
            "      (encoder): TransformerEncoder(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (embed_tokens): Embedding(15776, 512, padding_idx=1)\n",
            "        (embed_positions): SinusoidalPositionalEmbedding()\n",
            "        (layers): ModuleList(\n",
            "          (0): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (1): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (2): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (3): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (4): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (5): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (decoder): TransformerDecoder(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (embed_tokens): Embedding(6760, 512, padding_idx=1)\n",
            "        (embed_positions): SinusoidalPositionalEmbedding()\n",
            "        (layers): ModuleList(\n",
            "          (0): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (1): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (2): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (3): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (4): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (5): TransformerDecoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (output_projection): Linear(in_features=512, out_features=6760, bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2021-07-09 14:14:47 | INFO | fairseq_cli.train | task: MultilingualTranslationTask\n",
            "2021-07-09 14:14:47 | INFO | fairseq_cli.train | model: MultilingualTransformerModel\n",
            "2021-07-09 14:14:47 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2021-07-09 14:14:47 | INFO | fairseq_cli.train | num. shared model params: 62,014,464 (num. trained: 62,014,464)\n",
            "2021-07-09 14:14:47 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-07-09 14:14:48 | INFO | fairseq.data.data_utils | loaded 8,874 examples from: data-bin/mr_hi.en.bpe16k/valid.mr-en.mr\n",
            "2021-07-09 14:14:50 | INFO | fairseq.data.data_utils | loaded 8,874 examples from: data-bin/mr_hi.en.bpe16k/valid.mr-en.en\n",
            "2021-07-09 14:14:50 | INFO | fairseq.tasks.translation | data-bin/mr_hi.en.bpe16k/ valid mr-en 8874 examples\n",
            "2021-07-09 14:14:52 | INFO | fairseq.data.data_utils | loaded 6,307 examples from: data-bin/mr_hi.en.bpe16k/valid.hi-en.hi\n",
            "2021-07-09 14:14:54 | INFO | fairseq.data.data_utils | loaded 6,307 examples from: data-bin/mr_hi.en.bpe16k/valid.hi-en.en\n",
            "2021-07-09 14:14:54 | INFO | fairseq.tasks.translation | data-bin/mr_hi.en.bpe16k/ valid hi-en 6307 examples\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.embed_tokens.weight <- models.mr-en.decoder.output_projection.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.embed_tokens.weight <- models.hi-en.decoder.embed_tokens.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.embed_tokens.weight <- models.hi-en.decoder.output_projection.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.self_attn.k_proj.weight <- models.hi-en.decoder.layers.0.self_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.self_attn.k_proj.bias <- models.hi-en.decoder.layers.0.self_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.self_attn.v_proj.weight <- models.hi-en.decoder.layers.0.self_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.self_attn.v_proj.bias <- models.hi-en.decoder.layers.0.self_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.self_attn.q_proj.weight <- models.hi-en.decoder.layers.0.self_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.self_attn.q_proj.bias <- models.hi-en.decoder.layers.0.self_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.self_attn.out_proj.weight <- models.hi-en.decoder.layers.0.self_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.self_attn.out_proj.bias <- models.hi-en.decoder.layers.0.self_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.self_attn_layer_norm.weight <- models.hi-en.decoder.layers.0.self_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.self_attn_layer_norm.bias <- models.hi-en.decoder.layers.0.self_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.encoder_attn.k_proj.weight <- models.hi-en.decoder.layers.0.encoder_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.encoder_attn.k_proj.bias <- models.hi-en.decoder.layers.0.encoder_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.encoder_attn.v_proj.weight <- models.hi-en.decoder.layers.0.encoder_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.encoder_attn.v_proj.bias <- models.hi-en.decoder.layers.0.encoder_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.encoder_attn.q_proj.weight <- models.hi-en.decoder.layers.0.encoder_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.encoder_attn.q_proj.bias <- models.hi-en.decoder.layers.0.encoder_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.encoder_attn.out_proj.weight <- models.hi-en.decoder.layers.0.encoder_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.encoder_attn.out_proj.bias <- models.hi-en.decoder.layers.0.encoder_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.encoder_attn_layer_norm.weight <- models.hi-en.decoder.layers.0.encoder_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.encoder_attn_layer_norm.bias <- models.hi-en.decoder.layers.0.encoder_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.fc1.weight <- models.hi-en.decoder.layers.0.fc1.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.fc1.bias <- models.hi-en.decoder.layers.0.fc1.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.fc2.weight <- models.hi-en.decoder.layers.0.fc2.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.fc2.bias <- models.hi-en.decoder.layers.0.fc2.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.final_layer_norm.weight <- models.hi-en.decoder.layers.0.final_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.0.final_layer_norm.bias <- models.hi-en.decoder.layers.0.final_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.self_attn.k_proj.weight <- models.hi-en.decoder.layers.1.self_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.self_attn.k_proj.bias <- models.hi-en.decoder.layers.1.self_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.self_attn.v_proj.weight <- models.hi-en.decoder.layers.1.self_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.self_attn.v_proj.bias <- models.hi-en.decoder.layers.1.self_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.self_attn.q_proj.weight <- models.hi-en.decoder.layers.1.self_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.self_attn.q_proj.bias <- models.hi-en.decoder.layers.1.self_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.self_attn.out_proj.weight <- models.hi-en.decoder.layers.1.self_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.self_attn.out_proj.bias <- models.hi-en.decoder.layers.1.self_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.self_attn_layer_norm.weight <- models.hi-en.decoder.layers.1.self_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.self_attn_layer_norm.bias <- models.hi-en.decoder.layers.1.self_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.encoder_attn.k_proj.weight <- models.hi-en.decoder.layers.1.encoder_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.encoder_attn.k_proj.bias <- models.hi-en.decoder.layers.1.encoder_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.encoder_attn.v_proj.weight <- models.hi-en.decoder.layers.1.encoder_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.encoder_attn.v_proj.bias <- models.hi-en.decoder.layers.1.encoder_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.encoder_attn.q_proj.weight <- models.hi-en.decoder.layers.1.encoder_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.encoder_attn.q_proj.bias <- models.hi-en.decoder.layers.1.encoder_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.encoder_attn.out_proj.weight <- models.hi-en.decoder.layers.1.encoder_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.encoder_attn.out_proj.bias <- models.hi-en.decoder.layers.1.encoder_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.encoder_attn_layer_norm.weight <- models.hi-en.decoder.layers.1.encoder_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.encoder_attn_layer_norm.bias <- models.hi-en.decoder.layers.1.encoder_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.fc1.weight <- models.hi-en.decoder.layers.1.fc1.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.fc1.bias <- models.hi-en.decoder.layers.1.fc1.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.fc2.weight <- models.hi-en.decoder.layers.1.fc2.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.fc2.bias <- models.hi-en.decoder.layers.1.fc2.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.final_layer_norm.weight <- models.hi-en.decoder.layers.1.final_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.1.final_layer_norm.bias <- models.hi-en.decoder.layers.1.final_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.self_attn.k_proj.weight <- models.hi-en.decoder.layers.2.self_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.self_attn.k_proj.bias <- models.hi-en.decoder.layers.2.self_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.self_attn.v_proj.weight <- models.hi-en.decoder.layers.2.self_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.self_attn.v_proj.bias <- models.hi-en.decoder.layers.2.self_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.self_attn.q_proj.weight <- models.hi-en.decoder.layers.2.self_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.self_attn.q_proj.bias <- models.hi-en.decoder.layers.2.self_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.self_attn.out_proj.weight <- models.hi-en.decoder.layers.2.self_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.self_attn.out_proj.bias <- models.hi-en.decoder.layers.2.self_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.self_attn_layer_norm.weight <- models.hi-en.decoder.layers.2.self_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.self_attn_layer_norm.bias <- models.hi-en.decoder.layers.2.self_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.encoder_attn.k_proj.weight <- models.hi-en.decoder.layers.2.encoder_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.encoder_attn.k_proj.bias <- models.hi-en.decoder.layers.2.encoder_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.encoder_attn.v_proj.weight <- models.hi-en.decoder.layers.2.encoder_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.encoder_attn.v_proj.bias <- models.hi-en.decoder.layers.2.encoder_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.encoder_attn.q_proj.weight <- models.hi-en.decoder.layers.2.encoder_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.encoder_attn.q_proj.bias <- models.hi-en.decoder.layers.2.encoder_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.encoder_attn.out_proj.weight <- models.hi-en.decoder.layers.2.encoder_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.encoder_attn.out_proj.bias <- models.hi-en.decoder.layers.2.encoder_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.encoder_attn_layer_norm.weight <- models.hi-en.decoder.layers.2.encoder_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.encoder_attn_layer_norm.bias <- models.hi-en.decoder.layers.2.encoder_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.fc1.weight <- models.hi-en.decoder.layers.2.fc1.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.fc1.bias <- models.hi-en.decoder.layers.2.fc1.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.fc2.weight <- models.hi-en.decoder.layers.2.fc2.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.fc2.bias <- models.hi-en.decoder.layers.2.fc2.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.final_layer_norm.weight <- models.hi-en.decoder.layers.2.final_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.2.final_layer_norm.bias <- models.hi-en.decoder.layers.2.final_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.self_attn.k_proj.weight <- models.hi-en.decoder.layers.3.self_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.self_attn.k_proj.bias <- models.hi-en.decoder.layers.3.self_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.self_attn.v_proj.weight <- models.hi-en.decoder.layers.3.self_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.self_attn.v_proj.bias <- models.hi-en.decoder.layers.3.self_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.self_attn.q_proj.weight <- models.hi-en.decoder.layers.3.self_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.self_attn.q_proj.bias <- models.hi-en.decoder.layers.3.self_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.self_attn.out_proj.weight <- models.hi-en.decoder.layers.3.self_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.self_attn.out_proj.bias <- models.hi-en.decoder.layers.3.self_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.self_attn_layer_norm.weight <- models.hi-en.decoder.layers.3.self_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.self_attn_layer_norm.bias <- models.hi-en.decoder.layers.3.self_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.encoder_attn.k_proj.weight <- models.hi-en.decoder.layers.3.encoder_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.encoder_attn.k_proj.bias <- models.hi-en.decoder.layers.3.encoder_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.encoder_attn.v_proj.weight <- models.hi-en.decoder.layers.3.encoder_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.encoder_attn.v_proj.bias <- models.hi-en.decoder.layers.3.encoder_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.encoder_attn.q_proj.weight <- models.hi-en.decoder.layers.3.encoder_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.encoder_attn.q_proj.bias <- models.hi-en.decoder.layers.3.encoder_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.encoder_attn.out_proj.weight <- models.hi-en.decoder.layers.3.encoder_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.encoder_attn.out_proj.bias <- models.hi-en.decoder.layers.3.encoder_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.encoder_attn_layer_norm.weight <- models.hi-en.decoder.layers.3.encoder_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.encoder_attn_layer_norm.bias <- models.hi-en.decoder.layers.3.encoder_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.fc1.weight <- models.hi-en.decoder.layers.3.fc1.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.fc1.bias <- models.hi-en.decoder.layers.3.fc1.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.fc2.weight <- models.hi-en.decoder.layers.3.fc2.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.fc2.bias <- models.hi-en.decoder.layers.3.fc2.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.final_layer_norm.weight <- models.hi-en.decoder.layers.3.final_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.3.final_layer_norm.bias <- models.hi-en.decoder.layers.3.final_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.self_attn.k_proj.weight <- models.hi-en.decoder.layers.4.self_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.self_attn.k_proj.bias <- models.hi-en.decoder.layers.4.self_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.self_attn.v_proj.weight <- models.hi-en.decoder.layers.4.self_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.self_attn.v_proj.bias <- models.hi-en.decoder.layers.4.self_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.self_attn.q_proj.weight <- models.hi-en.decoder.layers.4.self_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.self_attn.q_proj.bias <- models.hi-en.decoder.layers.4.self_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.self_attn.out_proj.weight <- models.hi-en.decoder.layers.4.self_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.self_attn.out_proj.bias <- models.hi-en.decoder.layers.4.self_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.self_attn_layer_norm.weight <- models.hi-en.decoder.layers.4.self_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.self_attn_layer_norm.bias <- models.hi-en.decoder.layers.4.self_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.encoder_attn.k_proj.weight <- models.hi-en.decoder.layers.4.encoder_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.encoder_attn.k_proj.bias <- models.hi-en.decoder.layers.4.encoder_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.encoder_attn.v_proj.weight <- models.hi-en.decoder.layers.4.encoder_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.encoder_attn.v_proj.bias <- models.hi-en.decoder.layers.4.encoder_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.encoder_attn.q_proj.weight <- models.hi-en.decoder.layers.4.encoder_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.encoder_attn.q_proj.bias <- models.hi-en.decoder.layers.4.encoder_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.encoder_attn.out_proj.weight <- models.hi-en.decoder.layers.4.encoder_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.encoder_attn.out_proj.bias <- models.hi-en.decoder.layers.4.encoder_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.encoder_attn_layer_norm.weight <- models.hi-en.decoder.layers.4.encoder_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.encoder_attn_layer_norm.bias <- models.hi-en.decoder.layers.4.encoder_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.fc1.weight <- models.hi-en.decoder.layers.4.fc1.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.fc1.bias <- models.hi-en.decoder.layers.4.fc1.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.fc2.weight <- models.hi-en.decoder.layers.4.fc2.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.fc2.bias <- models.hi-en.decoder.layers.4.fc2.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.final_layer_norm.weight <- models.hi-en.decoder.layers.4.final_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.4.final_layer_norm.bias <- models.hi-en.decoder.layers.4.final_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.self_attn.k_proj.weight <- models.hi-en.decoder.layers.5.self_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.self_attn.k_proj.bias <- models.hi-en.decoder.layers.5.self_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.self_attn.v_proj.weight <- models.hi-en.decoder.layers.5.self_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.self_attn.v_proj.bias <- models.hi-en.decoder.layers.5.self_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.self_attn.q_proj.weight <- models.hi-en.decoder.layers.5.self_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.self_attn.q_proj.bias <- models.hi-en.decoder.layers.5.self_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.self_attn.out_proj.weight <- models.hi-en.decoder.layers.5.self_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.self_attn.out_proj.bias <- models.hi-en.decoder.layers.5.self_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.self_attn_layer_norm.weight <- models.hi-en.decoder.layers.5.self_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.self_attn_layer_norm.bias <- models.hi-en.decoder.layers.5.self_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.encoder_attn.k_proj.weight <- models.hi-en.decoder.layers.5.encoder_attn.k_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.encoder_attn.k_proj.bias <- models.hi-en.decoder.layers.5.encoder_attn.k_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.encoder_attn.v_proj.weight <- models.hi-en.decoder.layers.5.encoder_attn.v_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.encoder_attn.v_proj.bias <- models.hi-en.decoder.layers.5.encoder_attn.v_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.encoder_attn.q_proj.weight <- models.hi-en.decoder.layers.5.encoder_attn.q_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.encoder_attn.q_proj.bias <- models.hi-en.decoder.layers.5.encoder_attn.q_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.encoder_attn.out_proj.weight <- models.hi-en.decoder.layers.5.encoder_attn.out_proj.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.encoder_attn.out_proj.bias <- models.hi-en.decoder.layers.5.encoder_attn.out_proj.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.encoder_attn_layer_norm.weight <- models.hi-en.decoder.layers.5.encoder_attn_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.encoder_attn_layer_norm.bias <- models.hi-en.decoder.layers.5.encoder_attn_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.fc1.weight <- models.hi-en.decoder.layers.5.fc1.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.fc1.bias <- models.hi-en.decoder.layers.5.fc1.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.fc2.weight <- models.hi-en.decoder.layers.5.fc2.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.fc2.bias <- models.hi-en.decoder.layers.5.fc2.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.final_layer_norm.weight <- models.hi-en.decoder.layers.5.final_layer_norm.weight\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.layers.5.final_layer_norm.bias <- models.hi-en.decoder.layers.5.final_layer_norm.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | detected shared parameter: models.mr-en.decoder.output_projection.bias <- models.hi-en.decoder.output_projection.bias\n",
            "2021-07-09 14:15:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-07-09 14:15:03 | INFO | fairseq.utils | rank   0: capabilities =  3.7  ; total memory = 11.173 GB ; name = Tesla K80                               \n",
            "2021-07-09 14:15:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-07-09 14:15:03 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-07-09 14:15:03 | INFO | fairseq_cli.train | max tokens per device = 4000 and max sentences per device = None\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/multilingual_transformer/checkpoint_last.pt\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/multilingual_transformer/checkpoint_last.pt\n",
            "2021-07-09 14:15:03 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-07-09 14:15:11 | INFO | fairseq.data.data_utils | loaded 3,279,706 examples from: data-bin/mr_hi.en.bpe16k/train.mr-en.mr\n",
            "2021-07-09 14:15:22 | INFO | fairseq.data.data_utils | loaded 3,279,706 examples from: data-bin/mr_hi.en.bpe16k/train.mr-en.en\n",
            "2021-07-09 14:15:22 | INFO | fairseq.tasks.translation | data-bin/mr_hi.en.bpe16k/ train mr-en 3279706 examples\n",
            "2021-07-09 14:15:39 | INFO | fairseq.data.data_utils | loaded 8,456,698 examples from: data-bin/mr_hi.en.bpe16k/train.hi-en.hi\n",
            "2021-07-09 14:15:55 | INFO | fairseq.data.data_utils | loaded 8,456,698 examples from: data-bin/mr_hi.en.bpe16k/train.hi-en.en\n",
            "2021-07-09 14:15:55 | INFO | fairseq.tasks.translation | data-bin/mr_hi.en.bpe16k/ train hi-en 8456698 examples\n",
            "epoch 001:   0% 0/9057 [00:00<?, ?it/s]2021-07-09 14:16:33 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-07-09 14:16:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/drive/My Drive/MNMT_mr-hi-en_/fairseq/fairseq/utils.py:366: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "epoch 001:  18% 1653/9057 [3:06:36<14:00:44,  6.81s/it, loss=7.504, nll_loss=6.601, sample_size=37443.8, nsentences=1934.72, ntokens=37443.8, ppl=97.09, wps=5532.8, ups=0.15, wpb=37443.8, bsz=1934.7, num_updates=1600, lr=0.00020006, gnorm=0.795, train_wall=676, gb_free=8.4, wall=10934]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORVNJKb3OPoq",
        "outputId": "8f232b8a-577e-468c-a1a8-e92a27bed200"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul  6 11:00:28 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     8W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVUpJ-RqbsWv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}